{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Ph0UtS-7jVZ5",
        "outputId": "d362f9bc-fa04-4508-d856-51e46eb06dca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da92f324-79c9-47c5-8f73-1e23b7af7e72\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da92f324-79c9-47c5-8f73-1e23b7af7e72\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.csv to data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a6OChK4gpnB3",
        "outputId": "21e159e0-a6c6-4fcd-b200-a31d6b0228b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence Sentiment\n",
              "0  The GeoSolutions technology will leverage Bene...  positive\n",
              "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
              "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
              "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
              "4  The Swedish buyout firm has sold its remaining...   neutral"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58168dff-3bf7-4f03-99fd-2d76ea4b73a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58168dff-3bf7-4f03-99fd-2d76ea4b73a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58168dff-3bf7-4f03-99fd-2d76ea4b73a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58168dff-3bf7-4f03-99fd-2d76ea4b73a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b5aad5d2-2bca-44b2-b4c9-c927baa40ab9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5aad5d2-2bca-44b2-b4c9-c927baa40ab9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b5aad5d2-2bca-44b2-b4c9-c927baa40ab9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5842,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5322,\n        \"samples\": [\n          \"It is now the leading private road ambulance service company in Finland .\",\n          \"Finnish silicon wafers manufacturer Okmetic Oyj said it swung to a net profit of 4.9 mln euro $ 6.3 mln in the first nine months of 2006 from a net loss of 1.8 mln euro $ 2.3 mln a year earlier .\",\n          \"$GILD  is expanding its research facilities...keeping up with the pace of innovation  https://t.co/uOE7FJ4LOP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv(\"data.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "Fi32TLVCmtrz",
        "outputId": "3fb54d1d-4ba1-4a68-a41c-5863e6b9900c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Calculate the length of each sentence in terms of words\n",
        "sequence_lengths = [len(seq.split()) for seq in data[\"Sentence\"]]\n",
        "\n",
        "# Visualize the sentence lengths using a boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=sequence_lengths)\n",
        "plt.title('Box Plot of Sentence Lengths (Words)')\n",
        "plt.xlabel('Sentence Length (Words)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfXv-vJZXZ6G",
        "outputId": "51f64e15-9561-4496-ba90-1dfd713cedcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/6.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/6.8 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspellchecker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSOOb5G2LS8i"
      },
      "source": [
        "Base line Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3yqZ-ItrL_O",
        "outputId": "57b0af28-a8f5-4180-ed52-c86d72edd88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - accuracy: 0.5189 - loss: 1.0134 - val_accuracy: 0.5277 - val_loss: 0.9360\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.5469 - loss: 0.9197 - val_accuracy: 0.5864 - val_loss: 0.9053\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 180ms/step - accuracy: 0.6020 - loss: 0.8838 - val_accuracy: 0.5801 - val_loss: 0.9011\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.5971 - loss: 0.8812 - val_accuracy: 0.5819 - val_loss: 0.8910\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - accuracy: 0.6097 - loss: 0.8765 - val_accuracy: 0.5995 - val_loss: 0.8807\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 0.5973 - loss: 0.8592 - val_accuracy: 0.5916 - val_loss: 0.8799\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.6155 - loss: 0.8573 - val_accuracy: 0.5898 - val_loss: 0.8754\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.6045 - loss: 0.8562 - val_accuracy: 0.5910 - val_loss: 0.8718\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.6010 - loss: 0.8439 - val_accuracy: 0.5927 - val_loss: 0.8613\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - accuracy: 0.6152 - loss: 0.8431 - val_accuracy: 0.5961 - val_loss: 0.8755\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 270ms/step - accuracy: 0.6058 - loss: 0.8534 - val_accuracy: 0.5961 - val_loss: 0.8780\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 104ms/step - accuracy: 0.6109 - loss: 0.8359 - val_accuracy: 0.6075 - val_loss: 0.8602\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 179ms/step - accuracy: 0.6317 - loss: 0.8084 - val_accuracy: 0.6001 - val_loss: 0.8648\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - accuracy: 0.6195 - loss: 0.8143 - val_accuracy: 0.6127 - val_loss: 0.8704\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - accuracy: 0.6386 - loss: 0.8065 - val_accuracy: 0.6127 - val_loss: 0.8538\n",
            "Epoch 16/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 117ms/step - accuracy: 0.6534 - loss: 0.7788 - val_accuracy: 0.5978 - val_loss: 0.8592\n",
            "Epoch 17/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - accuracy: 0.6399 - loss: 0.7820 - val_accuracy: 0.6064 - val_loss: 0.8769\n",
            "Epoch 18/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - accuracy: 0.6586 - loss: 0.7790 - val_accuracy: 0.6149 - val_loss: 0.8553\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6139 - loss: 0.8419\n",
            "Test Accuracy: 0.61\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import itertools\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary resources from nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Get the set of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.add('also')\n",
        "\n",
        "# Define punctuation characters to be removed (excluding common currency symbols)\n",
        "currency_symbols = '$€£¥₹'\n",
        "punctuation_to_remove = string.punctuation.replace('$', '').replace('€', '').replace('£', '').replace('¥', '').replace('₹', '')\n",
        "\n",
        "# Function to preprocess text by lowercasing, removing punctuation, and lemmatizing\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase the text\n",
        "    text = re.sub(f\"[{re.escape(punctuation_to_remove)}]\", '', text)  # Remove unwanted punctuation\n",
        "    words = text.split()  # Tokenize by splitting on spaces\n",
        "    filtered_words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    return filtered_words\n",
        "# Assuming data['Sentence'] contains the text data as a list of sentences\n",
        "texts_lower = [preprocess_text(sentence) for sentence in data['Sentence']]  # Preprocess all sentences\n",
        "\n",
        "# Initialize Word2Vec model\n",
        "word2vec_model = Word2Vec(vector_size=50, window=5, sg=0, negative=2, min_count=1)\n",
        "\n",
        "# Build the vocabulary and train Word2Vec\n",
        "word2vec_model.build_vocab(texts_lower)\n",
        "word2vec_model.train(texts_lower, total_examples=word2vec_model.corpus_count, epochs=30)\n",
        "\n",
        "# Convert sentences to sequences of word vectors\n",
        "vectorized_sentences = []\n",
        "for sentence in texts_lower:\n",
        "    vectorized_sentence = [word2vec_model.wv[word] for word in sentence if word in word2vec_model.wv]\n",
        "    vectorized_sentences.append(vectorized_sentence)\n",
        "\n",
        "# Define the maximum sequence length for LSTM input\n",
        "max_sequence_length = 30  # Adjust based on your dataset and text length\n",
        "\n",
        "# Pad sequences to ensure uniform input length for the LSTM\n",
        "X = pad_sequences([np.array(sentence) for sentence in vectorized_sentences],\n",
        "                  maxlen=max_sequence_length,\n",
        "                  padding='post',\n",
        "                  dtype='float32')\n",
        "\n",
        "# Encode the labels (assuming binary or multiclass classification)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['Sentiment'])  # Assuming 'Sentiment' column exists in `data`\n",
        "y = tf.keras.utils.to_categorical(y)  # One-hot encode labels for multi-class classification\n",
        "\n",
        "# Add EarlyStopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build the LSTM model for text classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X.shape[1], X.shape[2])),\n",
        "    tf.keras.layers.LSTM(128, return_sequences=False),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(y.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=100, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcJy7G2Yy_39"
      },
      "source": [
        "include stop words and no Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQKW6AaiyxTT",
        "outputId": "2647cc64-3479-4630-9124-2daffac20a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 289ms/step - accuracy: 0.5371 - loss: 0.9789 - val_accuracy: 0.6212 - val_loss: 0.8947\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 181ms/step - accuracy: 0.6073 - loss: 0.8635 - val_accuracy: 0.6264 - val_loss: 0.8457\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - accuracy: 0.6258 - loss: 0.8313 - val_accuracy: 0.6229 - val_loss: 0.8392\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 170ms/step - accuracy: 0.6448 - loss: 0.8112 - val_accuracy: 0.6389 - val_loss: 0.8326\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 107ms/step - accuracy: 0.6417 - loss: 0.7995 - val_accuracy: 0.6338 - val_loss: 0.8156\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - accuracy: 0.6407 - loss: 0.7994 - val_accuracy: 0.6275 - val_loss: 0.8055\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.6500 - loss: 0.7693 - val_accuracy: 0.6349 - val_loss: 0.8081\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.6532 - loss: 0.7759 - val_accuracy: 0.6326 - val_loss: 0.8264\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - accuracy: 0.6717 - loss: 0.7243 - val_accuracy: 0.6286 - val_loss: 0.8090\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6334 - loss: 0.7956\n",
            "Test Accuracy: 0.63\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re# Function to preprocess text by lowercasing and removing punctuation (keeping stopwords)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase the text\n",
        "    text = re.sub(f\"[{re.escape(punctuation_to_remove)}]\", '', text)  # Remove unwanted punctuation\n",
        "    words = text.split()  # Tokenize by splitting on spaces\n",
        "    return words  # Return tokenized words, keeping stopwords\n",
        "\n",
        "# Assuming data['Sentence'] contains the text data as a list of sentences\n",
        "texts_lower = [preprocess_text(sentence) for sentence in data['Sentence']]  # Preprocess all sentences\n",
        "\n",
        "# Initialize Word2Vec model\n",
        "word2vec_model = Word2Vec(vector_size=50, window=5, sg=0, negative=2, min_count=1)\n",
        "\n",
        "# Build the vocabulary and train Word2Vec\n",
        "word2vec_model.build_vocab(texts_lower)\n",
        "word2vec_model.train(texts_lower, total_examples=word2vec_model.corpus_count, epochs=30)\n",
        "\n",
        "# Convert sentences to sequences of word vectors\n",
        "vectorized_sentences = []\n",
        "for sentence in texts_lower:\n",
        "    vectorized_sentence = [word2vec_model.wv[word] for word in sentence if word in word2vec_model.wv]\n",
        "    vectorized_sentences.append(vectorized_sentence)\n",
        "\n",
        "# Define the maximum sequence length for LSTM input\n",
        "max_sequence_length = 30  # Adjust based on your dataset and text length\n",
        "\n",
        "# Pad sequences to ensure uniform input length for the LSTM\n",
        "X = pad_sequences([np.array(sentence) for sentence in vectorized_sentences],\n",
        "                  maxlen=max_sequence_length,\n",
        "                  padding='post',\n",
        "                  dtype='float32')\n",
        "\n",
        "# Encode the labels (assuming binary or multiclass classification)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['Sentiment'])  # Assuming 'Sentiment' column exists in data\n",
        "y = tf.keras.utils.to_categorical(y)  # One-hot encode labels for multi-class classification\n",
        "\n",
        "# Add EarlyStopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build the LSTM model for text classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X.shape[1], X.shape[2])),\n",
        "    tf.keras.layers.LSTM(128, return_sequences=False),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(y.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=100, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Embeddings"
      ],
      "metadata": {
        "id": "WIavBEo5lRx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the list of words and their corresponding vectors\n",
        "words = list(word2vec_model.wv.index_to_key)  # Get all the words in the vocabulary\n",
        "\n",
        "# Select a subset of words (e.g., the first 50 words for simplicity)\n",
        "# You can change this to a more complex selection logic, such as filtering by frequency, word similarity, or a specific topic.\n",
        "selected_words = words[:50]  # Select the first 50 words for visualization\n",
        "\n",
        "# Get vectors only for the selected words\n",
        "selected_word_vectors = np.array([word2vec_model.wv[word] for word in selected_words])\n",
        "\n",
        "# Use t-SNE to reduce dimensionality of word vectors to 2D for visualization\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "reduced_vectors = tsne.fit_transform(selected_word_vectors)\n",
        "\n",
        "# Plot the reduced vectors using matplotlib\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.scatter(reduced_vectors[:, 0], reduced_vectors[:, 1])\n",
        "\n",
        "# Annotate the points with the corresponding words\n",
        "for i, word in enumerate(selected_words):\n",
        "    word = word.replace('$', r'\\$')  # Escape dollar signs if present\n",
        "    plt.annotate(word, xy=(reduced_vectors[i, 0], reduced_vectors[i, 1]))\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "0srZNf4wjxDo",
        "outputId": "de51337c-a349-4b40-b102-f4c9179bc52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKVLmJ8ULVS7"
      },
      "source": [
        "Hyper parameter Tuning for word2vec and LSTM parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYl6JxvydeCI",
        "outputId": "3c7f44b3-d947-4ef2-9640-72287b50b746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.5172 - loss: 1.0219 - val_accuracy: 0.5357 - val_loss: 0.9259\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5670 - loss: 0.8923 - val_accuracy: 0.6189 - val_loss: 0.8383\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.6275 - loss: 0.8327 - val_accuracy: 0.6435 - val_loss: 0.7924\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.6461 - loss: 0.7822 - val_accuracy: 0.6794 - val_loss: 0.7591\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.6785 - loss: 0.7317 - val_accuracy: 0.6800 - val_loss: 0.7264\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.6972 - loss: 0.6900 - val_accuracy: 0.6771 - val_loss: 0.7121\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.7275 - loss: 0.6330 - val_accuracy: 0.7039 - val_loss: 0.6884\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.7377 - loss: 0.6070 - val_accuracy: 0.6948 - val_loss: 0.6850\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7415 - loss: 0.5957 - val_accuracy: 0.7148 - val_loss: 0.7059\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.7514 - loss: 0.5729 - val_accuracy: 0.7136 - val_loss: 0.6736\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.7728 - loss: 0.5318 - val_accuracy: 0.7159 - val_loss: 0.6578\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.7841 - loss: 0.5123 - val_accuracy: 0.7119 - val_loss: 0.7211\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.7689 - loss: 0.5215 - val_accuracy: 0.7233 - val_loss: 0.6574\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7814 - loss: 0.4752 - val_accuracy: 0.7062 - val_loss: 0.6630\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.8053 - loss: 0.4292 - val_accuracy: 0.7108 - val_loss: 0.8036\n",
            "Epoch 16/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.8159 - loss: 0.4246 - val_accuracy: 0.6891 - val_loss: 0.7248\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7373 - loss: 0.6461\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.4946 - loss: 1.0263 - val_accuracy: 0.5345 - val_loss: 0.9170\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.5676 - loss: 0.8955 - val_accuracy: 0.6298 - val_loss: 0.8423\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6222 - loss: 0.8465 - val_accuracy: 0.6321 - val_loss: 0.8179\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.6307 - loss: 0.8298 - val_accuracy: 0.6400 - val_loss: 0.7920\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.6558 - loss: 0.7805 - val_accuracy: 0.6178 - val_loss: 0.8148\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.6588 - loss: 0.7659 - val_accuracy: 0.6651 - val_loss: 0.7639\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6736 - loss: 0.7281 - val_accuracy: 0.6891 - val_loss: 0.7420\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6924 - loss: 0.7048 - val_accuracy: 0.6731 - val_loss: 0.7457\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7210 - loss: 0.6414 - val_accuracy: 0.7039 - val_loss: 0.7043\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7316 - loss: 0.6254 - val_accuracy: 0.7022 - val_loss: 0.6928\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.7527 - loss: 0.5634 - val_accuracy: 0.7108 - val_loss: 0.6783\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.7617 - loss: 0.5320 - val_accuracy: 0.7136 - val_loss: 0.7206\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.7723 - loss: 0.5140 - val_accuracy: 0.6817 - val_loss: 0.8117\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7759 - loss: 0.5239 - val_accuracy: 0.7022 - val_loss: 0.7396\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7190 - loss: 0.6526\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.5114 - loss: 1.0249 - val_accuracy: 0.5374 - val_loss: 0.9298\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.5585 - loss: 0.9059 - val_accuracy: 0.6195 - val_loss: 0.8501\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6215 - loss: 0.8444 - val_accuracy: 0.6446 - val_loss: 0.8145\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.6519 - loss: 0.8071 - val_accuracy: 0.6554 - val_loss: 0.7879\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.6567 - loss: 0.7743 - val_accuracy: 0.6589 - val_loss: 0.7702\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.6639 - loss: 0.7464 - val_accuracy: 0.6612 - val_loss: 0.7531\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.6912 - loss: 0.7036 - val_accuracy: 0.6708 - val_loss: 0.7686\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7081 - loss: 0.6848 - val_accuracy: 0.6783 - val_loss: 0.7130\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7412 - loss: 0.6195 - val_accuracy: 0.6999 - val_loss: 0.6793\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7505 - loss: 0.5858 - val_accuracy: 0.6925 - val_loss: 0.6827\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7450 - loss: 0.5660 - val_accuracy: 0.7222 - val_loss: 0.6630\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.7591 - loss: 0.5597 - val_accuracy: 0.7125 - val_loss: 0.7179\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7694 - loss: 0.5357 - val_accuracy: 0.7108 - val_loss: 0.6818\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.7914 - loss: 0.4861 - val_accuracy: 0.7131 - val_loss: 0.6744\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7281 - loss: 0.6495\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.4594 - loss: 1.0468 - val_accuracy: 0.5317 - val_loss: 0.9366\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.5551 - loss: 0.9128 - val_accuracy: 0.6321 - val_loss: 0.8446\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6322 - loss: 0.8428 - val_accuracy: 0.6149 - val_loss: 0.8339\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.6684 - loss: 0.7914 - val_accuracy: 0.6497 - val_loss: 0.7968\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.6705 - loss: 0.7642 - val_accuracy: 0.6726 - val_loss: 0.7578\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6710 - loss: 0.7244 - val_accuracy: 0.6880 - val_loss: 0.7386\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7217 - loss: 0.6615 - val_accuracy: 0.7011 - val_loss: 0.7052\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.7150 - loss: 0.6460 - val_accuracy: 0.7051 - val_loss: 0.7052\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.7365 - loss: 0.6142 - val_accuracy: 0.7074 - val_loss: 0.6685\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7490 - loss: 0.5804 - val_accuracy: 0.7176 - val_loss: 0.6857\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.7604 - loss: 0.5492 - val_accuracy: 0.7085 - val_loss: 0.6785\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.7761 - loss: 0.5211 - val_accuracy: 0.7125 - val_loss: 0.6686\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7191 - loss: 0.6561\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.5092 - loss: 1.0077 - val_accuracy: 0.6127 - val_loss: 0.8718\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.6070 - loss: 0.8605 - val_accuracy: 0.6349 - val_loss: 0.8165\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.6417 - loss: 0.8038 - val_accuracy: 0.6469 - val_loss: 0.7957\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 145ms/step - accuracy: 0.6386 - loss: 0.8023 - val_accuracy: 0.6486 - val_loss: 0.7820\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.6875 - loss: 0.7132 - val_accuracy: 0.6880 - val_loss: 0.7243\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.7205 - loss: 0.6601 - val_accuracy: 0.7011 - val_loss: 0.7234\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.7226 - loss: 0.6570 - val_accuracy: 0.6914 - val_loss: 0.7002\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.7469 - loss: 0.5970 - val_accuracy: 0.7017 - val_loss: 0.6780\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.7520 - loss: 0.5784 - val_accuracy: 0.6948 - val_loss: 0.6907\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.7573 - loss: 0.5539 - val_accuracy: 0.7068 - val_loss: 0.6989\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.7861 - loss: 0.4971 - val_accuracy: 0.7005 - val_loss: 0.6904\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7023 - loss: 0.6639\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 126ms/step - accuracy: 0.4971 - loss: 1.0268 - val_accuracy: 0.6064 - val_loss: 0.8879\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 98ms/step - accuracy: 0.5924 - loss: 0.8745 - val_accuracy: 0.6281 - val_loss: 0.8193\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - accuracy: 0.6397 - loss: 0.8138 - val_accuracy: 0.6315 - val_loss: 0.8037\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.6239 - loss: 0.8236 - val_accuracy: 0.6275 - val_loss: 0.8116\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.6559 - loss: 0.7621 - val_accuracy: 0.6885 - val_loss: 0.7404\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.6860 - loss: 0.7090 - val_accuracy: 0.6783 - val_loss: 0.7180\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 138ms/step - accuracy: 0.7090 - loss: 0.6703 - val_accuracy: 0.6840 - val_loss: 0.6905\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.7130 - loss: 0.6508 - val_accuracy: 0.7045 - val_loss: 0.6666\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.7462 - loss: 0.5999 - val_accuracy: 0.7039 - val_loss: 0.6573\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 98ms/step - accuracy: 0.7457 - loss: 0.5732 - val_accuracy: 0.6942 - val_loss: 0.6997\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.7476 - loss: 0.5737 - val_accuracy: 0.7131 - val_loss: 0.6683\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.7779 - loss: 0.5151 - val_accuracy: 0.7216 - val_loss: 0.6517\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.7876 - loss: 0.4925 - val_accuracy: 0.7148 - val_loss: 0.6733\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.7927 - loss: 0.4715 - val_accuracy: 0.7119 - val_loss: 0.7004\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.8077 - loss: 0.4341 - val_accuracy: 0.7102 - val_loss: 0.7044\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7384 - loss: 0.6269\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - accuracy: 0.5237 - loss: 0.9989 - val_accuracy: 0.6132 - val_loss: 0.8668\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.6262 - loss: 0.8572 - val_accuracy: 0.6418 - val_loss: 0.8281\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.6553 - loss: 0.7934 - val_accuracy: 0.6389 - val_loss: 0.7894\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.6685 - loss: 0.7380 - val_accuracy: 0.6572 - val_loss: 0.7576\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.6809 - loss: 0.7162 - val_accuracy: 0.6492 - val_loss: 0.7495\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.7032 - loss: 0.6675 - val_accuracy: 0.6925 - val_loss: 0.7177\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.7354 - loss: 0.6397 - val_accuracy: 0.6920 - val_loss: 0.6916\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.7505 - loss: 0.5897 - val_accuracy: 0.6902 - val_loss: 0.6908\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7482 - loss: 0.5688 - val_accuracy: 0.6914 - val_loss: 0.6823\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.7643 - loss: 0.5437 - val_accuracy: 0.6925 - val_loss: 0.6948\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.7668 - loss: 0.5403 - val_accuracy: 0.6999 - val_loss: 0.6746\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.7741 - loss: 0.4968 - val_accuracy: 0.6999 - val_loss: 0.6940\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.7852 - loss: 0.4801 - val_accuracy: 0.6640 - val_loss: 0.7669\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7825 - loss: 0.4738 - val_accuracy: 0.7153 - val_loss: 0.7282\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7135 - loss: 0.6559\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - accuracy: 0.5196 - loss: 1.0093 - val_accuracy: 0.6167 - val_loss: 0.8679\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.6034 - loss: 0.8714 - val_accuracy: 0.6070 - val_loss: 0.8553\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.6453 - loss: 0.8196 - val_accuracy: 0.6378 - val_loss: 0.8046\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - accuracy: 0.6616 - loss: 0.7561 - val_accuracy: 0.6549 - val_loss: 0.7614\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.6779 - loss: 0.7372 - val_accuracy: 0.6366 - val_loss: 0.7870\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - accuracy: 0.6810 - loss: 0.7263 - val_accuracy: 0.6982 - val_loss: 0.6986\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.7195 - loss: 0.6562 - val_accuracy: 0.6777 - val_loss: 0.7064\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.7441 - loss: 0.6162 - val_accuracy: 0.7034 - val_loss: 0.6766\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.7570 - loss: 0.5724 - val_accuracy: 0.6925 - val_loss: 0.6811\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 155ms/step - accuracy: 0.7721 - loss: 0.5605 - val_accuracy: 0.7022 - val_loss: 0.6861\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - accuracy: 0.7778 - loss: 0.5396 - val_accuracy: 0.6942 - val_loss: 0.6701\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 134ms/step - accuracy: 0.7726 - loss: 0.5179 - val_accuracy: 0.6988 - val_loss: 0.6606\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.8001 - loss: 0.4613 - val_accuracy: 0.7108 - val_loss: 0.6976\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.8008 - loss: 0.4331 - val_accuracy: 0.6691 - val_loss: 0.7193\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.8109 - loss: 0.4573 - val_accuracy: 0.6942 - val_loss: 0.7606\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7037 - loss: 0.6433\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 287ms/step - accuracy: 0.5324 - loss: 0.9900 - val_accuracy: 0.6395 - val_loss: 0.8422\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 269ms/step - accuracy: 0.6505 - loss: 0.8234 - val_accuracy: 0.6406 - val_loss: 0.8003\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 226ms/step - accuracy: 0.6523 - loss: 0.7852 - val_accuracy: 0.6520 - val_loss: 0.8094\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 257ms/step - accuracy: 0.6652 - loss: 0.7764 - val_accuracy: 0.6748 - val_loss: 0.7546\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 271ms/step - accuracy: 0.7064 - loss: 0.6879 - val_accuracy: 0.6851 - val_loss: 0.7256\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - accuracy: 0.7149 - loss: 0.6627 - val_accuracy: 0.6754 - val_loss: 0.7068\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 273ms/step - accuracy: 0.7279 - loss: 0.6304 - val_accuracy: 0.6902 - val_loss: 0.6680\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 253ms/step - accuracy: 0.7436 - loss: 0.6000 - val_accuracy: 0.7062 - val_loss: 0.6926\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 269ms/step - accuracy: 0.7606 - loss: 0.5268 - val_accuracy: 0.6994 - val_loss: 0.6887\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 234ms/step - accuracy: 0.7730 - loss: 0.5471 - val_accuracy: 0.7096 - val_loss: 0.6990\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7135 - loss: 0.6452\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 235ms/step - accuracy: 0.5128 - loss: 0.9965 - val_accuracy: 0.5995 - val_loss: 0.8340\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 268ms/step - accuracy: 0.6077 - loss: 0.8493 - val_accuracy: 0.6383 - val_loss: 0.8182\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 266ms/step - accuracy: 0.6687 - loss: 0.7808 - val_accuracy: 0.6612 - val_loss: 0.7559\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 222ms/step - accuracy: 0.6739 - loss: 0.7470 - val_accuracy: 0.6771 - val_loss: 0.7397\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 254ms/step - accuracy: 0.6887 - loss: 0.7085 - val_accuracy: 0.6697 - val_loss: 0.7318\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step - accuracy: 0.6949 - loss: 0.6974 - val_accuracy: 0.6959 - val_loss: 0.7095\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 234ms/step - accuracy: 0.7220 - loss: 0.6588 - val_accuracy: 0.7056 - val_loss: 0.7016\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - accuracy: 0.7420 - loss: 0.6316 - val_accuracy: 0.7153 - val_loss: 0.6802\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 266ms/step - accuracy: 0.7545 - loss: 0.5879 - val_accuracy: 0.6999 - val_loss: 0.6998\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 248ms/step - accuracy: 0.7757 - loss: 0.5224 - val_accuracy: 0.7085 - val_loss: 0.6777\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 240ms/step - accuracy: 0.7508 - loss: 0.5468 - val_accuracy: 0.7142 - val_loss: 0.7092\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - accuracy: 0.7820 - loss: 0.5152 - val_accuracy: 0.6948 - val_loss: 0.6944\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 266ms/step - accuracy: 0.7895 - loss: 0.4911 - val_accuracy: 0.7188 - val_loss: 0.6647\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 228ms/step - accuracy: 0.8046 - loss: 0.4533 - val_accuracy: 0.7074 - val_loss: 0.6882\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 275ms/step - accuracy: 0.8312 - loss: 0.3996 - val_accuracy: 0.6954 - val_loss: 0.7630\n",
            "Epoch 16/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 266ms/step - accuracy: 0.8314 - loss: 0.3912 - val_accuracy: 0.6988 - val_loss: 0.7114\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7310 - loss: 0.6472\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 285ms/step - accuracy: 0.5011 - loss: 0.9875 - val_accuracy: 0.6246 - val_loss: 0.8536\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 267ms/step - accuracy: 0.6174 - loss: 0.8505 - val_accuracy: 0.6486 - val_loss: 0.8017\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 233ms/step - accuracy: 0.6565 - loss: 0.7695 - val_accuracy: 0.6651 - val_loss: 0.7777\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 243ms/step - accuracy: 0.6639 - loss: 0.7617 - val_accuracy: 0.6754 - val_loss: 0.7380\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 270ms/step - accuracy: 0.6868 - loss: 0.7146 - val_accuracy: 0.6982 - val_loss: 0.7012\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 238ms/step - accuracy: 0.7250 - loss: 0.6412 - val_accuracy: 0.6823 - val_loss: 0.7471\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - accuracy: 0.7234 - loss: 0.6464 - val_accuracy: 0.7017 - val_loss: 0.6767\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - accuracy: 0.7456 - loss: 0.6002 - val_accuracy: 0.6908 - val_loss: 0.7308\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 246ms/step - accuracy: 0.7602 - loss: 0.5707 - val_accuracy: 0.7210 - val_loss: 0.6704\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 261ms/step - accuracy: 0.7733 - loss: 0.5172 - val_accuracy: 0.6937 - val_loss: 0.6836\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 269ms/step - accuracy: 0.7545 - loss: 0.5445 - val_accuracy: 0.6971 - val_loss: 0.6725\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 232ms/step - accuracy: 0.7791 - loss: 0.5027 - val_accuracy: 0.6794 - val_loss: 0.7124\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.7227 - loss: 0.6688\n",
            "Training with combination: vector_size=200, window=10, negative=10, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 279ms/step - accuracy: 0.5190 - loss: 0.9983 - val_accuracy: 0.6144 - val_loss: 0.8646\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 247ms/step - accuracy: 0.6293 - loss: 0.8684 - val_accuracy: 0.6475 - val_loss: 0.7903\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 238ms/step - accuracy: 0.6571 - loss: 0.7755 - val_accuracy: 0.6737 - val_loss: 0.7536\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 270ms/step - accuracy: 0.6696 - loss: 0.7621 - val_accuracy: 0.6977 - val_loss: 0.7340\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 254ms/step - accuracy: 0.6810 - loss: 0.7214 - val_accuracy: 0.6714 - val_loss: 0.7248\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 271ms/step - accuracy: 0.6917 - loss: 0.6865 - val_accuracy: 0.7028 - val_loss: 0.6882\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 262ms/step - accuracy: 0.7302 - loss: 0.6383 - val_accuracy: 0.7056 - val_loss: 0.6669\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 263ms/step - accuracy: 0.7340 - loss: 0.6220 - val_accuracy: 0.6925 - val_loss: 0.6984\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 268ms/step - accuracy: 0.7524 - loss: 0.5853 - val_accuracy: 0.6908 - val_loss: 0.7216\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 261ms/step - accuracy: 0.7671 - loss: 0.5504 - val_accuracy: 0.7108 - val_loss: 0.7188\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7253 - loss: 0.6516\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.4778 - loss: 1.0313 - val_accuracy: 0.5282 - val_loss: 0.9498\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.5545 - loss: 0.9066 - val_accuracy: 0.6229 - val_loss: 0.8358\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.6389 - loss: 0.8180 - val_accuracy: 0.6475 - val_loss: 0.8000\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.6544 - loss: 0.7916 - val_accuracy: 0.6509 - val_loss: 0.7854\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.6657 - loss: 0.7559 - val_accuracy: 0.6651 - val_loss: 0.7546\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.6831 - loss: 0.7160 - val_accuracy: 0.6452 - val_loss: 0.7644\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.7014 - loss: 0.6861 - val_accuracy: 0.6988 - val_loss: 0.7177\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.7260 - loss: 0.6583 - val_accuracy: 0.7056 - val_loss: 0.6944\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.7458 - loss: 0.5746 - val_accuracy: 0.7022 - val_loss: 0.7023\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.7590 - loss: 0.5642 - val_accuracy: 0.6874 - val_loss: 0.6726\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.7732 - loss: 0.5470 - val_accuracy: 0.6686 - val_loss: 0.7080\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.7731 - loss: 0.5315 - val_accuracy: 0.6937 - val_loss: 0.6634\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.7786 - loss: 0.5000 - val_accuracy: 0.7091 - val_loss: 0.6753\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.8098 - loss: 0.4575 - val_accuracy: 0.6920 - val_loss: 0.6660\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8055 - loss: 0.4727 - val_accuracy: 0.7102 - val_loss: 0.6877\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7127 - loss: 0.6454\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 0.5132 - loss: 1.0298 - val_accuracy: 0.5334 - val_loss: 0.9228\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.5625 - loss: 0.9006 - val_accuracy: 0.6286 - val_loss: 0.8427\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.6260 - loss: 0.8388 - val_accuracy: 0.6440 - val_loss: 0.8198\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.6383 - loss: 0.8046 - val_accuracy: 0.6537 - val_loss: 0.7654\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.6532 - loss: 0.7682 - val_accuracy: 0.6492 - val_loss: 0.7590\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.6624 - loss: 0.7272 - val_accuracy: 0.6726 - val_loss: 0.7465\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.6928 - loss: 0.6944 - val_accuracy: 0.6811 - val_loss: 0.7195\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.7111 - loss: 0.6495 - val_accuracy: 0.6863 - val_loss: 0.7095\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.7353 - loss: 0.6215 - val_accuracy: 0.7102 - val_loss: 0.6871\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.7558 - loss: 0.5702 - val_accuracy: 0.7017 - val_loss: 0.6838\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7606 - loss: 0.5368 - val_accuracy: 0.6959 - val_loss: 0.7117\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.7724 - loss: 0.5190 - val_accuracy: 0.7051 - val_loss: 0.6856\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.7802 - loss: 0.4959 - val_accuracy: 0.7039 - val_loss: 0.7611\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7045 - loss: 0.6676\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.5040 - loss: 1.0361 - val_accuracy: 0.5317 - val_loss: 0.9694\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.5507 - loss: 0.9124 - val_accuracy: 0.6212 - val_loss: 0.8587\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.6263 - loss: 0.8403 - val_accuracy: 0.6475 - val_loss: 0.8166\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.6390 - loss: 0.8155 - val_accuracy: 0.6572 - val_loss: 0.8011\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.6634 - loss: 0.7789 - val_accuracy: 0.6452 - val_loss: 0.7991\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.6757 - loss: 0.7498 - val_accuracy: 0.6674 - val_loss: 0.7634\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.6764 - loss: 0.7327 - val_accuracy: 0.6834 - val_loss: 0.7195\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.7311 - loss: 0.6410 - val_accuracy: 0.6703 - val_loss: 0.7212\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7248 - loss: 0.6291 - val_accuracy: 0.7028 - val_loss: 0.6849\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.7459 - loss: 0.5966 - val_accuracy: 0.6971 - val_loss: 0.6951\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.7482 - loss: 0.5807 - val_accuracy: 0.7051 - val_loss: 0.6758\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.7752 - loss: 0.5317 - val_accuracy: 0.7022 - val_loss: 0.6943\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7835 - loss: 0.5113 - val_accuracy: 0.7171 - val_loss: 0.7522\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.7885 - loss: 0.4953 - val_accuracy: 0.6754 - val_loss: 0.7357\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7166 - loss: 0.6515\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 101ms/step - accuracy: 0.5057 - loss: 1.0292 - val_accuracy: 0.5345 - val_loss: 0.9387\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.5627 - loss: 0.9146 - val_accuracy: 0.6121 - val_loss: 0.8520\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6343 - loss: 0.8352 - val_accuracy: 0.6378 - val_loss: 0.8301\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6348 - loss: 0.8179 - val_accuracy: 0.6355 - val_loss: 0.8138\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.6541 - loss: 0.8009 - val_accuracy: 0.6617 - val_loss: 0.7601\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6686 - loss: 0.7477 - val_accuracy: 0.6549 - val_loss: 0.7516\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7073 - loss: 0.6862 - val_accuracy: 0.6925 - val_loss: 0.7022\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.7158 - loss: 0.6623 - val_accuracy: 0.6777 - val_loss: 0.7255\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.7323 - loss: 0.6290 - val_accuracy: 0.6880 - val_loss: 0.7188\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7515 - loss: 0.6055 - val_accuracy: 0.7051 - val_loss: 0.6931\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.7506 - loss: 0.5698 - val_accuracy: 0.7114 - val_loss: 0.6689\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7736 - loss: 0.5326 - val_accuracy: 0.7165 - val_loss: 0.7182\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.7676 - loss: 0.5268 - val_accuracy: 0.7074 - val_loss: 0.6818\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.7951 - loss: 0.4907 - val_accuracy: 0.7034 - val_loss: 0.7299\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7245 - loss: 0.6479\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.5219 - loss: 1.0111 - val_accuracy: 0.6207 - val_loss: 0.8884\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - accuracy: 0.6290 - loss: 0.8604 - val_accuracy: 0.6469 - val_loss: 0.8198\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 152ms/step - accuracy: 0.6679 - loss: 0.7854 - val_accuracy: 0.6714 - val_loss: 0.7572\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.6807 - loss: 0.7338 - val_accuracy: 0.6697 - val_loss: 0.7430\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step - accuracy: 0.7114 - loss: 0.6861 - val_accuracy: 0.6971 - val_loss: 0.7023\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - accuracy: 0.7248 - loss: 0.6621 - val_accuracy: 0.6880 - val_loss: 0.6878\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.7242 - loss: 0.6284 - val_accuracy: 0.6885 - val_loss: 0.7006\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - accuracy: 0.7285 - loss: 0.6181 - val_accuracy: 0.6925 - val_loss: 0.6998\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - accuracy: 0.7593 - loss: 0.5550 - val_accuracy: 0.7051 - val_loss: 0.6708\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.7723 - loss: 0.5292 - val_accuracy: 0.6994 - val_loss: 0.7324\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7651 - loss: 0.5432 - val_accuracy: 0.7091 - val_loss: 0.6886\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.7858 - loss: 0.4968 - val_accuracy: 0.6977 - val_loss: 0.6961\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7086 - loss: 0.6543\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - accuracy: 0.5019 - loss: 1.0321 - val_accuracy: 0.5682 - val_loss: 0.9260\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.5937 - loss: 0.8843 - val_accuracy: 0.6343 - val_loss: 0.8281\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.6350 - loss: 0.8163 - val_accuracy: 0.6480 - val_loss: 0.7949\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.6524 - loss: 0.7927 - val_accuracy: 0.6646 - val_loss: 0.8106\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.6785 - loss: 0.7402 - val_accuracy: 0.6492 - val_loss: 0.7571\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - accuracy: 0.7069 - loss: 0.6940 - val_accuracy: 0.7022 - val_loss: 0.6969\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 101ms/step - accuracy: 0.7198 - loss: 0.6437 - val_accuracy: 0.6874 - val_loss: 0.7369\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.7292 - loss: 0.6165 - val_accuracy: 0.7005 - val_loss: 0.6802\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.7494 - loss: 0.5961 - val_accuracy: 0.7125 - val_loss: 0.6636\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.7518 - loss: 0.5753 - val_accuracy: 0.7034 - val_loss: 0.6473\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.7810 - loss: 0.5236 - val_accuracy: 0.7022 - val_loss: 0.6763\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.7760 - loss: 0.5251 - val_accuracy: 0.7239 - val_loss: 0.6672\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.7830 - loss: 0.5011 - val_accuracy: 0.6851 - val_loss: 0.7110\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7076 - loss: 0.6253\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 127ms/step - accuracy: 0.5200 - loss: 0.9982 - val_accuracy: 0.6104 - val_loss: 0.8700\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.6275 - loss: 0.8409 - val_accuracy: 0.6372 - val_loss: 0.8182\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - accuracy: 0.6363 - loss: 0.8389 - val_accuracy: 0.6389 - val_loss: 0.8254\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - accuracy: 0.6673 - loss: 0.7857 - val_accuracy: 0.6589 - val_loss: 0.7886\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.6834 - loss: 0.7375 - val_accuracy: 0.6788 - val_loss: 0.7459\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 152ms/step - accuracy: 0.7063 - loss: 0.6917 - val_accuracy: 0.6589 - val_loss: 0.7613\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - accuracy: 0.7101 - loss: 0.6719 - val_accuracy: 0.6954 - val_loss: 0.7036\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - accuracy: 0.7144 - loss: 0.6623 - val_accuracy: 0.6811 - val_loss: 0.7857\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.7526 - loss: 0.5818 - val_accuracy: 0.6994 - val_loss: 0.6755\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step - accuracy: 0.7604 - loss: 0.5406 - val_accuracy: 0.7034 - val_loss: 0.6946\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - accuracy: 0.7757 - loss: 0.5312 - val_accuracy: 0.7074 - val_loss: 0.6652\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - accuracy: 0.7652 - loss: 0.5298 - val_accuracy: 0.6948 - val_loss: 0.7308\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - accuracy: 0.7862 - loss: 0.4888 - val_accuracy: 0.7096 - val_loss: 0.6924\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.8063 - loss: 0.4397 - val_accuracy: 0.6925 - val_loss: 0.7792\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7138 - loss: 0.6547\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.4963 - loss: 1.0167 - val_accuracy: 0.6207 - val_loss: 0.8594\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.6015 - loss: 0.8770 - val_accuracy: 0.6361 - val_loss: 0.8445\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.6605 - loss: 0.8163 - val_accuracy: 0.6286 - val_loss: 0.8277\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.6443 - loss: 0.7942 - val_accuracy: 0.6714 - val_loss: 0.7789\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.6895 - loss: 0.7350 - val_accuracy: 0.6708 - val_loss: 0.7514\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - accuracy: 0.6941 - loss: 0.7129 - val_accuracy: 0.6657 - val_loss: 0.7580\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.6970 - loss: 0.6996 - val_accuracy: 0.6748 - val_loss: 0.7225\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.7235 - loss: 0.6687 - val_accuracy: 0.7125 - val_loss: 0.6838\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.7396 - loss: 0.6126 - val_accuracy: 0.6885 - val_loss: 0.7125\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.7484 - loss: 0.5666 - val_accuracy: 0.7045 - val_loss: 0.6791\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 103ms/step - accuracy: 0.7617 - loss: 0.5521 - val_accuracy: 0.7074 - val_loss: 0.6670\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - accuracy: 0.7830 - loss: 0.4956 - val_accuracy: 0.7205 - val_loss: 0.6831\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.7876 - loss: 0.5054 - val_accuracy: 0.7159 - val_loss: 0.6737\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.8028 - loss: 0.4683 - val_accuracy: 0.6982 - val_loss: 0.7050\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.7090 - loss: 0.6477\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 283ms/step - accuracy: 0.5474 - loss: 0.9686 - val_accuracy: 0.6155 - val_loss: 0.8640\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 236ms/step - accuracy: 0.6250 - loss: 0.8446 - val_accuracy: 0.6497 - val_loss: 0.8027\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 267ms/step - accuracy: 0.6561 - loss: 0.7863 - val_accuracy: 0.6423 - val_loss: 0.7975\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 252ms/step - accuracy: 0.6519 - loss: 0.7913 - val_accuracy: 0.6726 - val_loss: 0.7735\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 226ms/step - accuracy: 0.6838 - loss: 0.7329 - val_accuracy: 0.6902 - val_loss: 0.7191\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 271ms/step - accuracy: 0.7014 - loss: 0.6998 - val_accuracy: 0.6845 - val_loss: 0.7199\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 268ms/step - accuracy: 0.7234 - loss: 0.6560 - val_accuracy: 0.6931 - val_loss: 0.6965\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 228ms/step - accuracy: 0.7386 - loss: 0.6255 - val_accuracy: 0.7011 - val_loss: 0.7006\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 274ms/step - accuracy: 0.7452 - loss: 0.5840 - val_accuracy: 0.7108 - val_loss: 0.6750\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 270ms/step - accuracy: 0.7583 - loss: 0.5645 - val_accuracy: 0.6965 - val_loss: 0.6979\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 226ms/step - accuracy: 0.7738 - loss: 0.5234 - val_accuracy: 0.7210 - val_loss: 0.6445\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 275ms/step - accuracy: 0.7905 - loss: 0.4809 - val_accuracy: 0.7102 - val_loss: 0.7077\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 277ms/step - accuracy: 0.7920 - loss: 0.4907 - val_accuracy: 0.7085 - val_loss: 0.7147\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 227ms/step - accuracy: 0.8129 - loss: 0.4272 - val_accuracy: 0.7051 - val_loss: 0.7354\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.7382 - loss: 0.6262\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 282ms/step - accuracy: 0.5162 - loss: 0.9889 - val_accuracy: 0.6264 - val_loss: 0.8469\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 268ms/step - accuracy: 0.6163 - loss: 0.8583 - val_accuracy: 0.6412 - val_loss: 0.8234\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 258ms/step - accuracy: 0.6555 - loss: 0.7967 - val_accuracy: 0.6612 - val_loss: 0.7705\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 235ms/step - accuracy: 0.6880 - loss: 0.7375 - val_accuracy: 0.6760 - val_loss: 0.7467\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 274ms/step - accuracy: 0.7033 - loss: 0.6933 - val_accuracy: 0.6686 - val_loss: 0.7487\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - accuracy: 0.7042 - loss: 0.6984 - val_accuracy: 0.6925 - val_loss: 0.7193\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 243ms/step - accuracy: 0.7372 - loss: 0.6271 - val_accuracy: 0.6982 - val_loss: 0.7072\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 281ms/step - accuracy: 0.7469 - loss: 0.6313 - val_accuracy: 0.6925 - val_loss: 0.7076\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 262ms/step - accuracy: 0.7504 - loss: 0.5662 - val_accuracy: 0.7193 - val_loss: 0.6895\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 228ms/step - accuracy: 0.7586 - loss: 0.5638 - val_accuracy: 0.6880 - val_loss: 0.7005\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 272ms/step - accuracy: 0.7717 - loss: 0.5551 - val_accuracy: 0.7171 - val_loss: 0.6934\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 296ms/step - accuracy: 0.7766 - loss: 0.5042 - val_accuracy: 0.7171 - val_loss: 0.7686\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.7227 - loss: 0.6764\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 270ms/step - accuracy: 0.5113 - loss: 1.0045 - val_accuracy: 0.5990 - val_loss: 0.8826\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 272ms/step - accuracy: 0.6192 - loss: 0.8484 - val_accuracy: 0.6161 - val_loss: 0.8142\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 224ms/step - accuracy: 0.6362 - loss: 0.7934 - val_accuracy: 0.6520 - val_loss: 0.8003\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 241ms/step - accuracy: 0.6631 - loss: 0.7588 - val_accuracy: 0.6737 - val_loss: 0.7401\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - accuracy: 0.6931 - loss: 0.6970 - val_accuracy: 0.6897 - val_loss: 0.7552\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 270ms/step - accuracy: 0.7099 - loss: 0.6800 - val_accuracy: 0.6777 - val_loss: 0.7055\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - accuracy: 0.7091 - loss: 0.6606 - val_accuracy: 0.6811 - val_loss: 0.7142\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 277ms/step - accuracy: 0.7368 - loss: 0.6242 - val_accuracy: 0.6965 - val_loss: 0.7184\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 252ms/step - accuracy: 0.7341 - loss: 0.6082 - val_accuracy: 0.7068 - val_loss: 0.6908\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 275ms/step - accuracy: 0.7639 - loss: 0.5572 - val_accuracy: 0.7096 - val_loss: 0.6569\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 278ms/step - accuracy: 0.7633 - loss: 0.5471 - val_accuracy: 0.6994 - val_loss: 0.6925\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 243ms/step - accuracy: 0.7935 - loss: 0.5101 - val_accuracy: 0.7017 - val_loss: 0.6714\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 272ms/step - accuracy: 0.7834 - loss: 0.4828 - val_accuracy: 0.7165 - val_loss: 0.6871\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7154 - loss: 0.6391\n",
            "Training with combination: vector_size=200, window=10, negative=20, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 235ms/step - accuracy: 0.5283 - loss: 0.9908 - val_accuracy: 0.6070 - val_loss: 0.8929\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 269ms/step - accuracy: 0.6232 - loss: 0.8576 - val_accuracy: 0.6423 - val_loss: 0.8257\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 265ms/step - accuracy: 0.6532 - loss: 0.7972 - val_accuracy: 0.6292 - val_loss: 0.8171\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - accuracy: 0.6477 - loss: 0.7835 - val_accuracy: 0.6720 - val_loss: 0.7622\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 275ms/step - accuracy: 0.6956 - loss: 0.7031 - val_accuracy: 0.6708 - val_loss: 0.7667\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 273ms/step - accuracy: 0.6870 - loss: 0.7231 - val_accuracy: 0.7062 - val_loss: 0.6940\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 234ms/step - accuracy: 0.7277 - loss: 0.6245 - val_accuracy: 0.6937 - val_loss: 0.6995\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 266ms/step - accuracy: 0.7435 - loss: 0.6138 - val_accuracy: 0.6937 - val_loss: 0.7125\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - accuracy: 0.7316 - loss: 0.6186 - val_accuracy: 0.7011 - val_loss: 0.6628\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 0.7447 - loss: 0.5868 - val_accuracy: 0.6823 - val_loss: 0.7098\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - accuracy: 0.7696 - loss: 0.5636 - val_accuracy: 0.6771 - val_loss: 0.7121\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 250ms/step - accuracy: 0.7729 - loss: 0.5206 - val_accuracy: 0.7125 - val_loss: 0.6709\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7107 - loss: 0.6533\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.5331 - loss: 0.9986 - val_accuracy: 0.6138 - val_loss: 0.8913\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6007 - loss: 0.8886 - val_accuracy: 0.6366 - val_loss: 0.8254\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6452 - loss: 0.8121 - val_accuracy: 0.6469 - val_loss: 0.8061\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.6647 - loss: 0.7647 - val_accuracy: 0.6880 - val_loss: 0.7280\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.6975 - loss: 0.7001 - val_accuracy: 0.6697 - val_loss: 0.7232\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.7061 - loss: 0.6624 - val_accuracy: 0.7045 - val_loss: 0.6767\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.7487 - loss: 0.6060 - val_accuracy: 0.6817 - val_loss: 0.6967\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.7473 - loss: 0.5934 - val_accuracy: 0.6868 - val_loss: 0.6986\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7646 - loss: 0.5655 - val_accuracy: 0.7228 - val_loss: 0.6946\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7153 - loss: 0.6555\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.4946 - loss: 1.0363 - val_accuracy: 0.5277 - val_loss: 0.9355\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.5501 - loss: 0.9141 - val_accuracy: 0.6275 - val_loss: 0.8386\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.6157 - loss: 0.8384 - val_accuracy: 0.6332 - val_loss: 0.8215\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.6396 - loss: 0.8094 - val_accuracy: 0.6583 - val_loss: 0.7905\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.6813 - loss: 0.7499 - val_accuracy: 0.6868 - val_loss: 0.7382\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7064 - loss: 0.6954 - val_accuracy: 0.6988 - val_loss: 0.6944\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7162 - loss: 0.6614 - val_accuracy: 0.6766 - val_loss: 0.7303\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.7259 - loss: 0.6407 - val_accuracy: 0.7034 - val_loss: 0.6984\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7484 - loss: 0.6261 - val_accuracy: 0.7022 - val_loss: 0.6682\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7691 - loss: 0.5696 - val_accuracy: 0.6748 - val_loss: 0.6959\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7633 - loss: 0.5523 - val_accuracy: 0.7034 - val_loss: 0.6625\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7548 - loss: 0.5483 - val_accuracy: 0.7210 - val_loss: 0.6626\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.7739 - loss: 0.5007 - val_accuracy: 0.6823 - val_loss: 0.6988\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.7941 - loss: 0.4986 - val_accuracy: 0.7022 - val_loss: 0.6574\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8104 - loss: 0.4383 - val_accuracy: 0.7039 - val_loss: 0.6887\n",
            "Epoch 16/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.8074 - loss: 0.4223 - val_accuracy: 0.7056 - val_loss: 0.7074\n",
            "Epoch 17/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.8263 - loss: 0.3933 - val_accuracy: 0.6959 - val_loss: 0.7312\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7126 - loss: 0.6278\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - accuracy: 0.4842 - loss: 1.0408 - val_accuracy: 0.5351 - val_loss: 0.9366\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.5657 - loss: 0.8993 - val_accuracy: 0.6252 - val_loss: 0.8361\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.6402 - loss: 0.8204 - val_accuracy: 0.6292 - val_loss: 0.8276\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.6654 - loss: 0.7755 - val_accuracy: 0.6503 - val_loss: 0.7903\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.6660 - loss: 0.7624 - val_accuracy: 0.6600 - val_loss: 0.7578\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.6878 - loss: 0.7150 - val_accuracy: 0.6629 - val_loss: 0.7585\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7261 - loss: 0.6619 - val_accuracy: 0.6880 - val_loss: 0.7004\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.7306 - loss: 0.6385 - val_accuracy: 0.6994 - val_loss: 0.6896\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.7544 - loss: 0.5853 - val_accuracy: 0.6834 - val_loss: 0.6934\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.7613 - loss: 0.5675 - val_accuracy: 0.7051 - val_loss: 0.7005\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.7768 - loss: 0.5214 - val_accuracy: 0.6686 - val_loss: 0.7242\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7118 - loss: 0.6635\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - accuracy: 0.4957 - loss: 1.0411 - val_accuracy: 0.5277 - val_loss: 0.9451\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.5390 - loss: 0.9118 - val_accuracy: 0.6138 - val_loss: 0.8606\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.6291 - loss: 0.8469 - val_accuracy: 0.6303 - val_loss: 0.8326\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.6338 - loss: 0.8266 - val_accuracy: 0.6315 - val_loss: 0.8088\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.6518 - loss: 0.7784 - val_accuracy: 0.6378 - val_loss: 0.8085\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.6670 - loss: 0.7702 - val_accuracy: 0.6651 - val_loss: 0.7561\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6843 - loss: 0.7235 - val_accuracy: 0.6737 - val_loss: 0.7398\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7134 - loss: 0.6672 - val_accuracy: 0.6851 - val_loss: 0.7132\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.7171 - loss: 0.6430 - val_accuracy: 0.6999 - val_loss: 0.6979\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7453 - loss: 0.5906 - val_accuracy: 0.6999 - val_loss: 0.6800\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7691 - loss: 0.5544 - val_accuracy: 0.6988 - val_loss: 0.7230\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7582 - loss: 0.5473 - val_accuracy: 0.7119 - val_loss: 0.6790\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.7825 - loss: 0.5037 - val_accuracy: 0.7056 - val_loss: 0.6796\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.7916 - loss: 0.4738 - val_accuracy: 0.7102 - val_loss: 0.7076\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.8038 - loss: 0.4310 - val_accuracy: 0.6891 - val_loss: 0.7518\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7211 - loss: 0.6546\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - accuracy: 0.5306 - loss: 0.9986 - val_accuracy: 0.5562 - val_loss: 0.8859\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - accuracy: 0.6064 - loss: 0.8420 - val_accuracy: 0.6172 - val_loss: 0.8293\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - accuracy: 0.6379 - loss: 0.7968 - val_accuracy: 0.6435 - val_loss: 0.7908\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.6779 - loss: 0.7387 - val_accuracy: 0.6959 - val_loss: 0.7193\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.6928 - loss: 0.6915 - val_accuracy: 0.6880 - val_loss: 0.7087\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.7070 - loss: 0.6777 - val_accuracy: 0.7068 - val_loss: 0.6919\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 155ms/step - accuracy: 0.7374 - loss: 0.6088 - val_accuracy: 0.7005 - val_loss: 0.6843\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 0.7640 - loss: 0.5889 - val_accuracy: 0.7011 - val_loss: 0.6984\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 147ms/step - accuracy: 0.7643 - loss: 0.5620 - val_accuracy: 0.7136 - val_loss: 0.6719\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.7779 - loss: 0.5214 - val_accuracy: 0.7085 - val_loss: 0.6770\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.7773 - loss: 0.5228 - val_accuracy: 0.7011 - val_loss: 0.7269\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.7856 - loss: 0.4796 - val_accuracy: 0.7114 - val_loss: 0.7515\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7265 - loss: 0.6495\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 0.5000 - loss: 1.0134 - val_accuracy: 0.5973 - val_loss: 0.9319\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.6007 - loss: 0.8714 - val_accuracy: 0.6395 - val_loss: 0.8092\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.6432 - loss: 0.7978 - val_accuracy: 0.6612 - val_loss: 0.7595\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.6818 - loss: 0.7443 - val_accuracy: 0.6708 - val_loss: 0.7637\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.7099 - loss: 0.6988 - val_accuracy: 0.6617 - val_loss: 0.7550\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.7064 - loss: 0.6875 - val_accuracy: 0.6999 - val_loss: 0.7129\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 155ms/step - accuracy: 0.7162 - loss: 0.6683 - val_accuracy: 0.7028 - val_loss: 0.6868\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.7465 - loss: 0.5862 - val_accuracy: 0.7039 - val_loss: 0.7141\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.7726 - loss: 0.5648 - val_accuracy: 0.7051 - val_loss: 0.6668\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step - accuracy: 0.7822 - loss: 0.5291 - val_accuracy: 0.6908 - val_loss: 0.6882\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 109ms/step - accuracy: 0.8056 - loss: 0.4717 - val_accuracy: 0.6868 - val_loss: 0.6846\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - accuracy: 0.7946 - loss: 0.4671 - val_accuracy: 0.6954 - val_loss: 0.7222\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7144 - loss: 0.6578\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 125ms/step - accuracy: 0.5377 - loss: 0.9993 - val_accuracy: 0.6115 - val_loss: 0.8904\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 157ms/step - accuracy: 0.6149 - loss: 0.8519 - val_accuracy: 0.6383 - val_loss: 0.7967\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 0.6579 - loss: 0.7769 - val_accuracy: 0.6720 - val_loss: 0.7594\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - accuracy: 0.6837 - loss: 0.7308 - val_accuracy: 0.6880 - val_loss: 0.7152\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.7235 - loss: 0.6679 - val_accuracy: 0.6868 - val_loss: 0.6849\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.7387 - loss: 0.6270 - val_accuracy: 0.6954 - val_loss: 0.7060\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.7302 - loss: 0.6306 - val_accuracy: 0.7011 - val_loss: 0.6902\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.7435 - loss: 0.5816 - val_accuracy: 0.7188 - val_loss: 0.6436\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.7740 - loss: 0.5222 - val_accuracy: 0.7210 - val_loss: 0.6404\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.7893 - loss: 0.4943 - val_accuracy: 0.7216 - val_loss: 0.6895\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.7886 - loss: 0.4861 - val_accuracy: 0.7142 - val_loss: 0.7126\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - accuracy: 0.8055 - loss: 0.4447 - val_accuracy: 0.7131 - val_loss: 0.6811\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7262 - loss: 0.6213\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - accuracy: 0.5035 - loss: 1.0194 - val_accuracy: 0.5722 - val_loss: 0.8788\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.6015 - loss: 0.8668 - val_accuracy: 0.6343 - val_loss: 0.8199\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.6534 - loss: 0.7994 - val_accuracy: 0.6532 - val_loss: 0.7866\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.6701 - loss: 0.7688 - val_accuracy: 0.6332 - val_loss: 0.8141\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.6625 - loss: 0.7440 - val_accuracy: 0.6577 - val_loss: 0.7967\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.6990 - loss: 0.7291 - val_accuracy: 0.6948 - val_loss: 0.7107\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.7110 - loss: 0.6532 - val_accuracy: 0.6880 - val_loss: 0.6986\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.7438 - loss: 0.6026 - val_accuracy: 0.6857 - val_loss: 0.7129\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 106ms/step - accuracy: 0.7414 - loss: 0.6067 - val_accuracy: 0.7068 - val_loss: 0.6705\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - accuracy: 0.7724 - loss: 0.5440 - val_accuracy: 0.6902 - val_loss: 0.6887\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 107ms/step - accuracy: 0.7721 - loss: 0.5274 - val_accuracy: 0.7034 - val_loss: 0.7054\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.7972 - loss: 0.4609 - val_accuracy: 0.7188 - val_loss: 0.7006\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7116 - loss: 0.6466\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 278ms/step - accuracy: 0.5265 - loss: 0.9802 - val_accuracy: 0.6098 - val_loss: 0.8635\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 274ms/step - accuracy: 0.6240 - loss: 0.8339 - val_accuracy: 0.6321 - val_loss: 0.8200\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 259ms/step - accuracy: 0.6450 - loss: 0.7773 - val_accuracy: 0.6634 - val_loss: 0.8020\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 275ms/step - accuracy: 0.6718 - loss: 0.7472 - val_accuracy: 0.6412 - val_loss: 0.8118\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 269ms/step - accuracy: 0.6874 - loss: 0.7449 - val_accuracy: 0.6925 - val_loss: 0.7554\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 279ms/step - accuracy: 0.7163 - loss: 0.6790 - val_accuracy: 0.6726 - val_loss: 0.7519\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 272ms/step - accuracy: 0.7302 - loss: 0.6434 - val_accuracy: 0.7011 - val_loss: 0.6639\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 245ms/step - accuracy: 0.7570 - loss: 0.5676 - val_accuracy: 0.7153 - val_loss: 0.6640\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 279ms/step - accuracy: 0.7700 - loss: 0.5550 - val_accuracy: 0.6874 - val_loss: 0.7341\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 275ms/step - accuracy: 0.7544 - loss: 0.5790 - val_accuracy: 0.7091 - val_loss: 0.6616\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.7863 - loss: 0.5054 - val_accuracy: 0.7119 - val_loss: 0.6885\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 258ms/step - accuracy: 0.7929 - loss: 0.4761 - val_accuracy: 0.6999 - val_loss: 0.7123\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 270ms/step - accuracy: 0.8105 - loss: 0.4383 - val_accuracy: 0.7131 - val_loss: 0.7506\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7112 - loss: 0.6479\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 238ms/step - accuracy: 0.5270 - loss: 0.9811 - val_accuracy: 0.6269 - val_loss: 0.8290\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 273ms/step - accuracy: 0.6307 - loss: 0.8345 - val_accuracy: 0.6458 - val_loss: 0.7978\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 274ms/step - accuracy: 0.6437 - loss: 0.7986 - val_accuracy: 0.6663 - val_loss: 0.7503\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 241ms/step - accuracy: 0.6819 - loss: 0.7221 - val_accuracy: 0.6766 - val_loss: 0.7612\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 277ms/step - accuracy: 0.6778 - loss: 0.7407 - val_accuracy: 0.6994 - val_loss: 0.7189\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 273ms/step - accuracy: 0.7194 - loss: 0.6496 - val_accuracy: 0.7125 - val_loss: 0.6954\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 279ms/step - accuracy: 0.7595 - loss: 0.6126 - val_accuracy: 0.6834 - val_loss: 0.7144\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 264ms/step - accuracy: 0.7250 - loss: 0.6354 - val_accuracy: 0.7096 - val_loss: 0.6677\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 234ms/step - accuracy: 0.7401 - loss: 0.5809 - val_accuracy: 0.6914 - val_loss: 0.6900\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 276ms/step - accuracy: 0.7592 - loss: 0.5669 - val_accuracy: 0.6982 - val_loss: 0.6842\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 279ms/step - accuracy: 0.7682 - loss: 0.5194 - val_accuracy: 0.6999 - val_loss: 0.8558\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7237 - loss: 0.6513\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 275ms/step - accuracy: 0.4985 - loss: 1.0004 - val_accuracy: 0.6281 - val_loss: 0.8439\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 272ms/step - accuracy: 0.6147 - loss: 0.8523 - val_accuracy: 0.6509 - val_loss: 0.7883\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 264ms/step - accuracy: 0.6611 - loss: 0.7797 - val_accuracy: 0.6731 - val_loss: 0.8160\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 278ms/step - accuracy: 0.6894 - loss: 0.7300 - val_accuracy: 0.6754 - val_loss: 0.7725\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 275ms/step - accuracy: 0.7128 - loss: 0.6720 - val_accuracy: 0.6920 - val_loss: 0.7503\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - accuracy: 0.7301 - loss: 0.6362 - val_accuracy: 0.7034 - val_loss: 0.6769\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 282ms/step - accuracy: 0.7408 - loss: 0.6171 - val_accuracy: 0.6589 - val_loss: 0.7300\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 277ms/step - accuracy: 0.7434 - loss: 0.5980 - val_accuracy: 0.7091 - val_loss: 0.7086\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 282ms/step - accuracy: 0.7717 - loss: 0.5493 - val_accuracy: 0.6931 - val_loss: 0.6658\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 280ms/step - accuracy: 0.7902 - loss: 0.5142 - val_accuracy: 0.7034 - val_loss: 0.6926\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 279ms/step - accuracy: 0.7801 - loss: 0.4886 - val_accuracy: 0.6982 - val_loss: 0.6599\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 280ms/step - accuracy: 0.8086 - loss: 0.4616 - val_accuracy: 0.6811 - val_loss: 0.6845\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 262ms/step - accuracy: 0.7853 - loss: 0.4754 - val_accuracy: 0.7062 - val_loss: 0.7466\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.8099 - loss: 0.4259 - val_accuracy: 0.6971 - val_loss: 0.7193\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7141 - loss: 0.6301\n",
            "Training with combination: vector_size=200, window=25, negative=10, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 279ms/step - accuracy: 0.5217 - loss: 0.9936 - val_accuracy: 0.6349 - val_loss: 0.8376\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.6344 - loss: 0.8266 - val_accuracy: 0.6503 - val_loss: 0.7883\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 229ms/step - accuracy: 0.6356 - loss: 0.7999 - val_accuracy: 0.6549 - val_loss: 0.7856\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 272ms/step - accuracy: 0.6880 - loss: 0.7481 - val_accuracy: 0.6748 - val_loss: 0.7354\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 280ms/step - accuracy: 0.7056 - loss: 0.6842 - val_accuracy: 0.6931 - val_loss: 0.7231\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 230ms/step - accuracy: 0.7094 - loss: 0.6787 - val_accuracy: 0.6920 - val_loss: 0.7207\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 267ms/step - accuracy: 0.7227 - loss: 0.6566 - val_accuracy: 0.6942 - val_loss: 0.6804\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 273ms/step - accuracy: 0.7400 - loss: 0.5925 - val_accuracy: 0.7205 - val_loss: 0.6734\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 229ms/step - accuracy: 0.7544 - loss: 0.5740 - val_accuracy: 0.7034 - val_loss: 0.6989\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 267ms/step - accuracy: 0.7634 - loss: 0.5463 - val_accuracy: 0.7188 - val_loss: 0.7053\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 276ms/step - accuracy: 0.7838 - loss: 0.5021 - val_accuracy: 0.7079 - val_loss: 0.6961\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7142 - loss: 0.6544\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 0.4719 - loss: 1.0446 - val_accuracy: 0.5305 - val_loss: 0.9543\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.5614 - loss: 0.9125 - val_accuracy: 0.6178 - val_loss: 0.8596\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6450 - loss: 0.8265 - val_accuracy: 0.6395 - val_loss: 0.8249\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.6581 - loss: 0.7846 - val_accuracy: 0.6497 - val_loss: 0.8143\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.6705 - loss: 0.7685 - val_accuracy: 0.6760 - val_loss: 0.7522\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.7001 - loss: 0.6991 - val_accuracy: 0.6766 - val_loss: 0.7329\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.6980 - loss: 0.6861 - val_accuracy: 0.6971 - val_loss: 0.6979\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.7228 - loss: 0.6432 - val_accuracy: 0.7028 - val_loss: 0.7079\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.7320 - loss: 0.6212 - val_accuracy: 0.7068 - val_loss: 0.6702\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.7415 - loss: 0.6146 - val_accuracy: 0.7045 - val_loss: 0.6652\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.7578 - loss: 0.5672 - val_accuracy: 0.6937 - val_loss: 0.7047\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7600 - loss: 0.5510 - val_accuracy: 0.7165 - val_loss: 0.6750\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7857 - loss: 0.4908 - val_accuracy: 0.7142 - val_loss: 0.7030\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7171 - loss: 0.6469\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.4807 - loss: 1.0334 - val_accuracy: 0.5339 - val_loss: 0.9551\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.5509 - loss: 0.9319 - val_accuracy: 0.6264 - val_loss: 0.8503\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.6112 - loss: 0.8595 - val_accuracy: 0.6207 - val_loss: 0.8343\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.6367 - loss: 0.8187 - val_accuracy: 0.6549 - val_loss: 0.7826\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.6637 - loss: 0.7569 - val_accuracy: 0.6691 - val_loss: 0.7602\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.6903 - loss: 0.7318 - val_accuracy: 0.6657 - val_loss: 0.7277\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.7110 - loss: 0.6748 - val_accuracy: 0.6885 - val_loss: 0.7063\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.7403 - loss: 0.6278 - val_accuracy: 0.6840 - val_loss: 0.7091\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.7355 - loss: 0.6035 - val_accuracy: 0.7005 - val_loss: 0.6850\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.7666 - loss: 0.5501 - val_accuracy: 0.7114 - val_loss: 0.6714\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7695 - loss: 0.5416 - val_accuracy: 0.7159 - val_loss: 0.6921\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 103ms/step - accuracy: 0.7875 - loss: 0.5196 - val_accuracy: 0.7108 - val_loss: 0.6929\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7996 - loss: 0.4828 - val_accuracy: 0.7091 - val_loss: 0.7255\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7198 - loss: 0.6562\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.4802 - loss: 1.0414 - val_accuracy: 0.5271 - val_loss: 0.9579\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.5630 - loss: 0.9057 - val_accuracy: 0.6195 - val_loss: 0.8636\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.6254 - loss: 0.8280 - val_accuracy: 0.6372 - val_loss: 0.8270\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.6298 - loss: 0.8151 - val_accuracy: 0.6207 - val_loss: 0.8226\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.6530 - loss: 0.7719 - val_accuracy: 0.6612 - val_loss: 0.7792\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.6600 - loss: 0.7608 - val_accuracy: 0.6703 - val_loss: 0.7535\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.6906 - loss: 0.7068 - val_accuracy: 0.6651 - val_loss: 0.7569\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.7080 - loss: 0.6733 - val_accuracy: 0.6914 - val_loss: 0.7067\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.7396 - loss: 0.6246 - val_accuracy: 0.6857 - val_loss: 0.6954\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.7464 - loss: 0.6027 - val_accuracy: 0.6977 - val_loss: 0.6831\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7644 - loss: 0.5654 - val_accuracy: 0.6840 - val_loss: 0.6947\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7744 - loss: 0.5439 - val_accuracy: 0.6840 - val_loss: 0.6833\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.7893 - loss: 0.4917 - val_accuracy: 0.6931 - val_loss: 0.6940\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7096 - loss: 0.6651\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.4950 - loss: 1.0369 - val_accuracy: 0.5328 - val_loss: 0.9458\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.5775 - loss: 0.9036 - val_accuracy: 0.6292 - val_loss: 0.8452\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 0.6237 - loss: 0.8402 - val_accuracy: 0.6298 - val_loss: 0.8386\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.6388 - loss: 0.8238 - val_accuracy: 0.6452 - val_loss: 0.8081\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.6594 - loss: 0.7739 - val_accuracy: 0.6543 - val_loss: 0.7807\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.6828 - loss: 0.7401 - val_accuracy: 0.6583 - val_loss: 0.7746\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.7049 - loss: 0.7103 - val_accuracy: 0.6629 - val_loss: 0.7264\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7110 - loss: 0.6641 - val_accuracy: 0.6897 - val_loss: 0.6997\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.7340 - loss: 0.6116 - val_accuracy: 0.7045 - val_loss: 0.6964\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.7364 - loss: 0.6098 - val_accuracy: 0.6977 - val_loss: 0.6860\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7396 - loss: 0.5882 - val_accuracy: 0.6965 - val_loss: 0.6840\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.7588 - loss: 0.5382 - val_accuracy: 0.7171 - val_loss: 0.6819\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.7966 - loss: 0.4902 - val_accuracy: 0.6885 - val_loss: 0.7124\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.7928 - loss: 0.4921 - val_accuracy: 0.6999 - val_loss: 0.6773\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.8130 - loss: 0.4450 - val_accuracy: 0.7119 - val_loss: 0.6795\n",
            "Epoch 16/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.8002 - loss: 0.4599 - val_accuracy: 0.7096 - val_loss: 0.7048\n",
            "Epoch 17/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.8227 - loss: 0.4103 - val_accuracy: 0.7148 - val_loss: 0.7884\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7118 - loss: 0.6619\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - accuracy: 0.5023 - loss: 1.0123 - val_accuracy: 0.6138 - val_loss: 0.8676\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.6012 - loss: 0.8585 - val_accuracy: 0.6349 - val_loss: 0.8162\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.6393 - loss: 0.7958 - val_accuracy: 0.6646 - val_loss: 0.7765\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - accuracy: 0.6792 - loss: 0.7329 - val_accuracy: 0.6788 - val_loss: 0.7300\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.6909 - loss: 0.7103 - val_accuracy: 0.6874 - val_loss: 0.6874\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.7184 - loss: 0.6562 - val_accuracy: 0.6965 - val_loss: 0.6829\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.7359 - loss: 0.6008 - val_accuracy: 0.6823 - val_loss: 0.6884\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 112ms/step - accuracy: 0.7550 - loss: 0.5654 - val_accuracy: 0.6817 - val_loss: 0.7116\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - accuracy: 0.7734 - loss: 0.5422 - val_accuracy: 0.7199 - val_loss: 0.7030\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7054 - loss: 0.6737\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - accuracy: 0.5082 - loss: 1.0261 - val_accuracy: 0.5579 - val_loss: 0.8957\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.5904 - loss: 0.8639 - val_accuracy: 0.6275 - val_loss: 0.8438\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.6407 - loss: 0.8067 - val_accuracy: 0.6326 - val_loss: 0.8053\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.6484 - loss: 0.7809 - val_accuracy: 0.6612 - val_loss: 0.7713\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - accuracy: 0.6856 - loss: 0.7317 - val_accuracy: 0.6800 - val_loss: 0.7252\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - accuracy: 0.7093 - loss: 0.6734 - val_accuracy: 0.6663 - val_loss: 0.7289\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - accuracy: 0.7300 - loss: 0.6404 - val_accuracy: 0.6931 - val_loss: 0.7034\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - accuracy: 0.7548 - loss: 0.5948 - val_accuracy: 0.6959 - val_loss: 0.7210\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - accuracy: 0.7484 - loss: 0.5955 - val_accuracy: 0.6891 - val_loss: 0.6853\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.7872 - loss: 0.5156 - val_accuracy: 0.7062 - val_loss: 0.6638\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - accuracy: 0.7802 - loss: 0.5019 - val_accuracy: 0.7062 - val_loss: 0.7027\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.8026 - loss: 0.4708 - val_accuracy: 0.6982 - val_loss: 0.6965\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.8045 - loss: 0.4525 - val_accuracy: 0.7114 - val_loss: 0.6836\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7129 - loss: 0.6365\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - accuracy: 0.4837 - loss: 1.0135 - val_accuracy: 0.6001 - val_loss: 0.8664\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.6197 - loss: 0.8523 - val_accuracy: 0.6298 - val_loss: 0.8199\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.6435 - loss: 0.7992 - val_accuracy: 0.6406 - val_loss: 0.7891\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.6575 - loss: 0.7639 - val_accuracy: 0.6737 - val_loss: 0.7431\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 155ms/step - accuracy: 0.6958 - loss: 0.7034 - val_accuracy: 0.6851 - val_loss: 0.7218\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - accuracy: 0.7222 - loss: 0.6616 - val_accuracy: 0.6783 - val_loss: 0.7182\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - accuracy: 0.7431 - loss: 0.6217 - val_accuracy: 0.6948 - val_loss: 0.7153\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - accuracy: 0.7390 - loss: 0.5935 - val_accuracy: 0.7171 - val_loss: 0.6774\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.7601 - loss: 0.5585 - val_accuracy: 0.6988 - val_loss: 0.6764\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.7671 - loss: 0.5358 - val_accuracy: 0.6908 - val_loss: 0.6773\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 0.7926 - loss: 0.5068 - val_accuracy: 0.7199 - val_loss: 0.6713\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.7948 - loss: 0.4702 - val_accuracy: 0.7039 - val_loss: 0.7073\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.8095 - loss: 0.4546 - val_accuracy: 0.7085 - val_loss: 0.7199\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.8089 - loss: 0.4268 - val_accuracy: 0.7159 - val_loss: 0.7594\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7387 - loss: 0.6381\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.4910 - loss: 1.0292 - val_accuracy: 0.5396 - val_loss: 0.9243\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.5773 - loss: 0.8923 - val_accuracy: 0.6326 - val_loss: 0.8282\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.6469 - loss: 0.8054 - val_accuracy: 0.6366 - val_loss: 0.7992\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 142ms/step - accuracy: 0.6438 - loss: 0.7989 - val_accuracy: 0.6583 - val_loss: 0.7661\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.6774 - loss: 0.7390 - val_accuracy: 0.6623 - val_loss: 0.7369\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.6988 - loss: 0.6887 - val_accuracy: 0.6817 - val_loss: 0.7310\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - accuracy: 0.7028 - loss: 0.6786 - val_accuracy: 0.6691 - val_loss: 0.7519\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.7260 - loss: 0.6390 - val_accuracy: 0.6885 - val_loss: 0.7120\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - accuracy: 0.7341 - loss: 0.6256 - val_accuracy: 0.7028 - val_loss: 0.6891\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.7575 - loss: 0.5757 - val_accuracy: 0.7051 - val_loss: 0.7106\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 111ms/step - accuracy: 0.7685 - loss: 0.5308 - val_accuracy: 0.7034 - val_loss: 0.7002\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - accuracy: 0.7742 - loss: 0.5148 - val_accuracy: 0.6908 - val_loss: 0.7122\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7082 - loss: 0.6743\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - accuracy: 0.5278 - loss: 0.9888 - val_accuracy: 0.6104 - val_loss: 0.8735\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 263ms/step - accuracy: 0.6217 - loss: 0.8425 - val_accuracy: 0.6326 - val_loss: 0.8172\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 279ms/step - accuracy: 0.6392 - loss: 0.7892 - val_accuracy: 0.6600 - val_loss: 0.7622\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.6844 - loss: 0.7349 - val_accuracy: 0.6686 - val_loss: 0.7738\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 276ms/step - accuracy: 0.6923 - loss: 0.6976 - val_accuracy: 0.6920 - val_loss: 0.7174\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 282ms/step - accuracy: 0.7121 - loss: 0.6610 - val_accuracy: 0.6908 - val_loss: 0.7328\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 274ms/step - accuracy: 0.7331 - loss: 0.6042 - val_accuracy: 0.6703 - val_loss: 0.7137\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 276ms/step - accuracy: 0.7474 - loss: 0.5800 - val_accuracy: 0.7114 - val_loss: 0.6828\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 278ms/step - accuracy: 0.7635 - loss: 0.5649 - val_accuracy: 0.7102 - val_loss: 0.6750\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 238ms/step - accuracy: 0.7763 - loss: 0.5436 - val_accuracy: 0.7159 - val_loss: 0.6617\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 278ms/step - accuracy: 0.7709 - loss: 0.5200 - val_accuracy: 0.7028 - val_loss: 0.6948\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.7987 - loss: 0.4653 - val_accuracy: 0.6908 - val_loss: 0.6641\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 247ms/step - accuracy: 0.8046 - loss: 0.4443 - val_accuracy: 0.7085 - val_loss: 0.7252\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7310 - loss: 0.6286\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 280ms/step - accuracy: 0.5192 - loss: 0.9987 - val_accuracy: 0.5944 - val_loss: 0.9183\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.6233 - loss: 0.8776 - val_accuracy: 0.6292 - val_loss: 0.7965\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 275ms/step - accuracy: 0.6446 - loss: 0.7938 - val_accuracy: 0.6680 - val_loss: 0.7505\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 278ms/step - accuracy: 0.6860 - loss: 0.7197 - val_accuracy: 0.6828 - val_loss: 0.7144\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 230ms/step - accuracy: 0.7026 - loss: 0.6870 - val_accuracy: 0.6823 - val_loss: 0.7560\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.7234 - loss: 0.6400 - val_accuracy: 0.6783 - val_loss: 0.7178\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 279ms/step - accuracy: 0.7414 - loss: 0.6049 - val_accuracy: 0.6840 - val_loss: 0.6997\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 277ms/step - accuracy: 0.7397 - loss: 0.5861 - val_accuracy: 0.7091 - val_loss: 0.6695\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 280ms/step - accuracy: 0.7656 - loss: 0.5401 - val_accuracy: 0.7153 - val_loss: 0.6685\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.7740 - loss: 0.5161 - val_accuracy: 0.6988 - val_loss: 0.6753\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 273ms/step - accuracy: 0.7872 - loss: 0.5047 - val_accuracy: 0.6463 - val_loss: 0.7628\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 286ms/step - accuracy: 0.7852 - loss: 0.4998 - val_accuracy: 0.6931 - val_loss: 0.6955\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.7321 - loss: 0.6396\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 249ms/step - accuracy: 0.5324 - loss: 0.9867 - val_accuracy: 0.6195 - val_loss: 0.8686\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 272ms/step - accuracy: 0.6191 - loss: 0.8563 - val_accuracy: 0.6372 - val_loss: 0.8380\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 266ms/step - accuracy: 0.6303 - loss: 0.8269 - val_accuracy: 0.6566 - val_loss: 0.7816\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 275ms/step - accuracy: 0.6832 - loss: 0.7295 - val_accuracy: 0.6617 - val_loss: 0.7545\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 278ms/step - accuracy: 0.7111 - loss: 0.6829 - val_accuracy: 0.6560 - val_loss: 0.7707\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.7118 - loss: 0.6768 - val_accuracy: 0.6920 - val_loss: 0.7150\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 271ms/step - accuracy: 0.7357 - loss: 0.5954 - val_accuracy: 0.6788 - val_loss: 0.7164\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 282ms/step - accuracy: 0.7414 - loss: 0.6089 - val_accuracy: 0.6623 - val_loss: 0.7265\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 239ms/step - accuracy: 0.7479 - loss: 0.5614 - val_accuracy: 0.6937 - val_loss: 0.7335\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.6904 - loss: 0.6973\n",
            "Training with combination: vector_size=200, window=25, negative=20, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.4802 - loss: 1.0228 - val_accuracy: 0.6081 - val_loss: 0.8732\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - accuracy: 0.6289 - loss: 0.8546 - val_accuracy: 0.6275 - val_loss: 0.8365\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 231ms/step - accuracy: 0.6373 - loss: 0.8199 - val_accuracy: 0.6486 - val_loss: 0.7758\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 270ms/step - accuracy: 0.6657 - loss: 0.7702 - val_accuracy: 0.6828 - val_loss: 0.7343\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 279ms/step - accuracy: 0.7089 - loss: 0.7051 - val_accuracy: 0.6908 - val_loss: 0.7109\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 241ms/step - accuracy: 0.7207 - loss: 0.6749 - val_accuracy: 0.6897 - val_loss: 0.7058\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 262ms/step - accuracy: 0.7382 - loss: 0.6322 - val_accuracy: 0.7102 - val_loss: 0.6800\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 285ms/step - accuracy: 0.7588 - loss: 0.5559 - val_accuracy: 0.7228 - val_loss: 0.6482\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 253ms/step - accuracy: 0.7782 - loss: 0.5494 - val_accuracy: 0.7142 - val_loss: 0.6612\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 279ms/step - accuracy: 0.7769 - loss: 0.5398 - val_accuracy: 0.7142 - val_loss: 0.6476\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 232ms/step - accuracy: 0.7831 - loss: 0.5073 - val_accuracy: 0.7102 - val_loss: 0.6698\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 276ms/step - accuracy: 0.8047 - loss: 0.4514 - val_accuracy: 0.7125 - val_loss: 0.6974\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 284ms/step - accuracy: 0.7991 - loss: 0.4616 - val_accuracy: 0.7131 - val_loss: 0.7470\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.7241 - loss: 0.6188\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.4889 - loss: 1.0413 - val_accuracy: 0.5299 - val_loss: 0.9541\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.5635 - loss: 0.9078 - val_accuracy: 0.6235 - val_loss: 0.8653\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6304 - loss: 0.8314 - val_accuracy: 0.6475 - val_loss: 0.8260\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.6557 - loss: 0.7935 - val_accuracy: 0.6423 - val_loss: 0.7979\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - accuracy: 0.6623 - loss: 0.7606 - val_accuracy: 0.6857 - val_loss: 0.7299\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.6815 - loss: 0.7210 - val_accuracy: 0.6805 - val_loss: 0.7221\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.7097 - loss: 0.6732 - val_accuracy: 0.6902 - val_loss: 0.7048\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.7243 - loss: 0.6315 - val_accuracy: 0.7079 - val_loss: 0.7300\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.7449 - loss: 0.5808 - val_accuracy: 0.6999 - val_loss: 0.6963\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.7531 - loss: 0.5711 - val_accuracy: 0.7125 - val_loss: 0.6714\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.7742 - loss: 0.5236 - val_accuracy: 0.6959 - val_loss: 0.6880\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.7888 - loss: 0.4840 - val_accuracy: 0.7079 - val_loss: 0.7176\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.7841 - loss: 0.4850 - val_accuracy: 0.7017 - val_loss: 0.7389\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7293 - loss: 0.6446\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - accuracy: 0.5119 - loss: 1.0238 - val_accuracy: 0.5317 - val_loss: 0.9203\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.5702 - loss: 0.8945 - val_accuracy: 0.6241 - val_loss: 0.8427\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.6282 - loss: 0.8382 - val_accuracy: 0.6309 - val_loss: 0.8389\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - accuracy: 0.6408 - loss: 0.8164 - val_accuracy: 0.6400 - val_loss: 0.7994\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.6451 - loss: 0.7854 - val_accuracy: 0.6463 - val_loss: 0.7735\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.6796 - loss: 0.7524 - val_accuracy: 0.6594 - val_loss: 0.7568\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.6813 - loss: 0.7333 - val_accuracy: 0.6771 - val_loss: 0.7275\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.6992 - loss: 0.6977 - val_accuracy: 0.6885 - val_loss: 0.7166\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.7258 - loss: 0.6365 - val_accuracy: 0.7017 - val_loss: 0.6900\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.7289 - loss: 0.6233 - val_accuracy: 0.7119 - val_loss: 0.6583\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.7711 - loss: 0.5486 - val_accuracy: 0.7165 - val_loss: 0.6491\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.7618 - loss: 0.5602 - val_accuracy: 0.7205 - val_loss: 0.6705\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.7865 - loss: 0.4973 - val_accuracy: 0.7074 - val_loss: 0.6666\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.7918 - loss: 0.4833 - val_accuracy: 0.7176 - val_loss: 0.6763\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7253 - loss: 0.6329\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4639 - loss: 1.0318 - val_accuracy: 0.5305 - val_loss: 0.9350\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.5810 - loss: 0.8933 - val_accuracy: 0.6315 - val_loss: 0.8450\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.6369 - loss: 0.8362 - val_accuracy: 0.6412 - val_loss: 0.8175\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6284 - loss: 0.8320 - val_accuracy: 0.6497 - val_loss: 0.8012\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.6569 - loss: 0.7964 - val_accuracy: 0.6515 - val_loss: 0.7822\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.6705 - loss: 0.7588 - val_accuracy: 0.6572 - val_loss: 0.7674\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.6836 - loss: 0.7258 - val_accuracy: 0.6794 - val_loss: 0.7316\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.7094 - loss: 0.6715 - val_accuracy: 0.6982 - val_loss: 0.6951\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.7252 - loss: 0.6328 - val_accuracy: 0.7022 - val_loss: 0.6857\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.7385 - loss: 0.5932 - val_accuracy: 0.7022 - val_loss: 0.6826\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.7431 - loss: 0.5804 - val_accuracy: 0.7108 - val_loss: 0.6617\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.7683 - loss: 0.5376 - val_accuracy: 0.7136 - val_loss: 0.6734\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.7759 - loss: 0.5057 - val_accuracy: 0.6999 - val_loss: 0.6827\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7951 - loss: 0.4780 - val_accuracy: 0.7045 - val_loss: 0.6749\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7131 - loss: 0.6490\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.4797 - loss: 1.0470 - val_accuracy: 0.5288 - val_loss: 0.9551\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.5495 - loss: 0.9247 - val_accuracy: 0.6092 - val_loss: 0.8749\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.6138 - loss: 0.8680 - val_accuracy: 0.6321 - val_loss: 0.8391\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - accuracy: 0.6458 - loss: 0.8226 - val_accuracy: 0.6577 - val_loss: 0.7858\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.6579 - loss: 0.7811 - val_accuracy: 0.6577 - val_loss: 0.7893\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.6824 - loss: 0.7467 - val_accuracy: 0.6560 - val_loss: 0.7742\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.6852 - loss: 0.7268 - val_accuracy: 0.6908 - val_loss: 0.7063\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.7174 - loss: 0.6764 - val_accuracy: 0.7034 - val_loss: 0.6965\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.7337 - loss: 0.6284 - val_accuracy: 0.7056 - val_loss: 0.6846\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step - accuracy: 0.7502 - loss: 0.5838 - val_accuracy: 0.7045 - val_loss: 0.6719\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.7571 - loss: 0.5816 - val_accuracy: 0.7074 - val_loss: 0.6772\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7670 - loss: 0.5371 - val_accuracy: 0.7256 - val_loss: 0.6707\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 128ms/step - accuracy: 0.7742 - loss: 0.5065 - val_accuracy: 0.7148 - val_loss: 0.6646\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.7900 - loss: 0.4923 - val_accuracy: 0.7205 - val_loss: 0.6941\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.7846 - loss: 0.4746 - val_accuracy: 0.7165 - val_loss: 0.7076\n",
            "Epoch 16/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.8106 - loss: 0.4509 - val_accuracy: 0.6868 - val_loss: 0.6996\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7298 - loss: 0.6348\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - accuracy: 0.5135 - loss: 1.0080 - val_accuracy: 0.6098 - val_loss: 0.8662\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.6274 - loss: 0.8464 - val_accuracy: 0.6343 - val_loss: 0.8254\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.6568 - loss: 0.8062 - val_accuracy: 0.6554 - val_loss: 0.7763\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.6703 - loss: 0.7459 - val_accuracy: 0.6743 - val_loss: 0.7364\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 167ms/step - accuracy: 0.6959 - loss: 0.6952 - val_accuracy: 0.6509 - val_loss: 0.7554\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 122ms/step - accuracy: 0.7075 - loss: 0.6693 - val_accuracy: 0.6885 - val_loss: 0.6786\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - accuracy: 0.7408 - loss: 0.6027 - val_accuracy: 0.6937 - val_loss: 0.7265\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.7270 - loss: 0.6271 - val_accuracy: 0.7011 - val_loss: 0.7105\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 0.7566 - loss: 0.5635 - val_accuracy: 0.7028 - val_loss: 0.6584\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.7771 - loss: 0.5045 - val_accuracy: 0.7045 - val_loss: 0.6578\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.7881 - loss: 0.4849 - val_accuracy: 0.6977 - val_loss: 0.7045\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - accuracy: 0.7827 - loss: 0.4771 - val_accuracy: 0.7045 - val_loss: 0.7058\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - accuracy: 0.8039 - loss: 0.4499 - val_accuracy: 0.6977 - val_loss: 0.7054\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.7165 - loss: 0.6420\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 129ms/step - accuracy: 0.5212 - loss: 0.9862 - val_accuracy: 0.6303 - val_loss: 0.8508\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - accuracy: 0.6446 - loss: 0.8293 - val_accuracy: 0.6577 - val_loss: 0.7823\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.6517 - loss: 0.7620 - val_accuracy: 0.6617 - val_loss: 0.7572\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 142ms/step - accuracy: 0.6723 - loss: 0.7331 - val_accuracy: 0.6897 - val_loss: 0.7239\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - accuracy: 0.7040 - loss: 0.6977 - val_accuracy: 0.7039 - val_loss: 0.6969\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - accuracy: 0.7343 - loss: 0.6270 - val_accuracy: 0.7034 - val_loss: 0.6890\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.7287 - loss: 0.6259 - val_accuracy: 0.6840 - val_loss: 0.6780\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.7380 - loss: 0.5895 - val_accuracy: 0.6697 - val_loss: 0.7174\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.7607 - loss: 0.5483 - val_accuracy: 0.7159 - val_loss: 0.6496\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 145ms/step - accuracy: 0.7761 - loss: 0.5230 - val_accuracy: 0.7062 - val_loss: 0.6828\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - accuracy: 0.7760 - loss: 0.4967 - val_accuracy: 0.7068 - val_loss: 0.7271\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - accuracy: 0.7900 - loss: 0.4825 - val_accuracy: 0.7034 - val_loss: 0.6911\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7313 - loss: 0.6380\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 132ms/step - accuracy: 0.5394 - loss: 1.0081 - val_accuracy: 0.5933 - val_loss: 0.8796\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.6110 - loss: 0.8609 - val_accuracy: 0.6400 - val_loss: 0.8096\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.6349 - loss: 0.8113 - val_accuracy: 0.6492 - val_loss: 0.7664\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.6739 - loss: 0.7445 - val_accuracy: 0.6663 - val_loss: 0.7470\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.7134 - loss: 0.6841 - val_accuracy: 0.6891 - val_loss: 0.6838\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.7257 - loss: 0.6417 - val_accuracy: 0.7079 - val_loss: 0.6679\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 165ms/step - accuracy: 0.7238 - loss: 0.6332 - val_accuracy: 0.6902 - val_loss: 0.6827\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 121ms/step - accuracy: 0.7406 - loss: 0.5834 - val_accuracy: 0.6965 - val_loss: 0.6738\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.7687 - loss: 0.5362 - val_accuracy: 0.6937 - val_loss: 0.6722\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7067 - loss: 0.6611\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 173ms/step - accuracy: 0.5224 - loss: 1.0083 - val_accuracy: 0.6167 - val_loss: 0.8695\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 121ms/step - accuracy: 0.6117 - loss: 0.8559 - val_accuracy: 0.6269 - val_loss: 0.8329\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - accuracy: 0.6483 - loss: 0.8020 - val_accuracy: 0.6828 - val_loss: 0.7485\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.6909 - loss: 0.7368 - val_accuracy: 0.6754 - val_loss: 0.7318\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.6967 - loss: 0.6994 - val_accuracy: 0.6726 - val_loss: 0.7148\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.7234 - loss: 0.6692 - val_accuracy: 0.6925 - val_loss: 0.7244\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - accuracy: 0.7247 - loss: 0.6320 - val_accuracy: 0.6971 - val_loss: 0.6811\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.7422 - loss: 0.5934 - val_accuracy: 0.6572 - val_loss: 0.7324\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - accuracy: 0.7486 - loss: 0.5554 - val_accuracy: 0.6988 - val_loss: 0.6932\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 120ms/step - accuracy: 0.7585 - loss: 0.5524 - val_accuracy: 0.7051 - val_loss: 0.6800\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - accuracy: 0.7836 - loss: 0.5136 - val_accuracy: 0.7034 - val_loss: 0.6790\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - accuracy: 0.7823 - loss: 0.4823 - val_accuracy: 0.6920 - val_loss: 0.7077\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.7973 - loss: 0.4558 - val_accuracy: 0.7079 - val_loss: 0.6693\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.8248 - loss: 0.4296 - val_accuracy: 0.6994 - val_loss: 0.7346\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.8075 - loss: 0.4186 - val_accuracy: 0.6811 - val_loss: 0.7327\n",
            "Epoch 16/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.8179 - loss: 0.4047 - val_accuracy: 0.6834 - val_loss: 0.8092\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7178 - loss: 0.6577\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - accuracy: 0.4990 - loss: 1.0015 - val_accuracy: 0.6372 - val_loss: 0.8511\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.6372 - loss: 0.8398 - val_accuracy: 0.6281 - val_loss: 0.8231\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 0.6468 - loss: 0.7960 - val_accuracy: 0.6646 - val_loss: 0.7887\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 306ms/step - accuracy: 0.6593 - loss: 0.7658 - val_accuracy: 0.6309 - val_loss: 0.7999\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 299ms/step - accuracy: 0.6880 - loss: 0.7006 - val_accuracy: 0.6703 - val_loss: 0.7347\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 269ms/step - accuracy: 0.7105 - loss: 0.6727 - val_accuracy: 0.7108 - val_loss: 0.7078\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 309ms/step - accuracy: 0.7272 - loss: 0.6313 - val_accuracy: 0.6657 - val_loss: 0.6807\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.7548 - loss: 0.5754 - val_accuracy: 0.7017 - val_loss: 0.6922\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 308ms/step - accuracy: 0.7608 - loss: 0.5641 - val_accuracy: 0.6800 - val_loss: 0.7236\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 314ms/step - accuracy: 0.7628 - loss: 0.5560 - val_accuracy: 0.7034 - val_loss: 0.6643\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 276ms/step - accuracy: 0.7882 - loss: 0.5000 - val_accuracy: 0.7119 - val_loss: 0.6776\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 311ms/step - accuracy: 0.7926 - loss: 0.4710 - val_accuracy: 0.7102 - val_loss: 0.6751\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 308ms/step - accuracy: 0.7974 - loss: 0.4575 - val_accuracy: 0.7102 - val_loss: 0.6771\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7162 - loss: 0.6588\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 314ms/step - accuracy: 0.4878 - loss: 1.0038 - val_accuracy: 0.6161 - val_loss: 0.8534\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 301ms/step - accuracy: 0.6349 - loss: 0.8374 - val_accuracy: 0.6509 - val_loss: 0.8097\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 315ms/step - accuracy: 0.6620 - loss: 0.7766 - val_accuracy: 0.6332 - val_loss: 0.7922\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 295ms/step - accuracy: 0.6640 - loss: 0.7496 - val_accuracy: 0.6788 - val_loss: 0.7246\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 272ms/step - accuracy: 0.6926 - loss: 0.7064 - val_accuracy: 0.6937 - val_loss: 0.7874\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 311ms/step - accuracy: 0.7019 - loss: 0.7023 - val_accuracy: 0.7056 - val_loss: 0.6796\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 311ms/step - accuracy: 0.7381 - loss: 0.6285 - val_accuracy: 0.7142 - val_loss: 0.6815\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.7497 - loss: 0.5805 - val_accuracy: 0.7034 - val_loss: 0.6849\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 304ms/step - accuracy: 0.7632 - loss: 0.5656 - val_accuracy: 0.7079 - val_loss: 0.6875\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7135 - loss: 0.6629\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 309ms/step - accuracy: 0.4885 - loss: 1.0228 - val_accuracy: 0.6275 - val_loss: 0.8711\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 308ms/step - accuracy: 0.6311 - loss: 0.8565 - val_accuracy: 0.6338 - val_loss: 0.8247\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 289ms/step - accuracy: 0.6448 - loss: 0.8086 - val_accuracy: 0.6212 - val_loss: 0.8384\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - accuracy: 0.6594 - loss: 0.7789 - val_accuracy: 0.6594 - val_loss: 0.7722\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 298ms/step - accuracy: 0.6798 - loss: 0.7288 - val_accuracy: 0.6788 - val_loss: 0.7244\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 305ms/step - accuracy: 0.7137 - loss: 0.6953 - val_accuracy: 0.7034 - val_loss: 0.6908\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 307ms/step - accuracy: 0.7284 - loss: 0.6284 - val_accuracy: 0.6766 - val_loss: 0.7359\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 311ms/step - accuracy: 0.7296 - loss: 0.6385 - val_accuracy: 0.6942 - val_loss: 0.7160\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 277ms/step - accuracy: 0.7454 - loss: 0.5806 - val_accuracy: 0.7165 - val_loss: 0.6937\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7160 - loss: 0.6701\n",
            "Training with combination: vector_size=300, window=10, negative=10, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 307ms/step - accuracy: 0.5172 - loss: 1.0010 - val_accuracy: 0.6252 - val_loss: 0.8449\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 306ms/step - accuracy: 0.6353 - loss: 0.8539 - val_accuracy: 0.6440 - val_loss: 0.8116\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 292ms/step - accuracy: 0.6413 - loss: 0.8088 - val_accuracy: 0.6423 - val_loss: 0.8061\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 310ms/step - accuracy: 0.6578 - loss: 0.7772 - val_accuracy: 0.6680 - val_loss: 0.7685\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 294ms/step - accuracy: 0.6861 - loss: 0.7421 - val_accuracy: 0.6771 - val_loss: 0.7363\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 301ms/step - accuracy: 0.7040 - loss: 0.6896 - val_accuracy: 0.6800 - val_loss: 0.7309\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 306ms/step - accuracy: 0.7182 - loss: 0.6518 - val_accuracy: 0.7005 - val_loss: 0.7170\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 309ms/step - accuracy: 0.7234 - loss: 0.6518 - val_accuracy: 0.7091 - val_loss: 0.6644\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 297ms/step - accuracy: 0.7553 - loss: 0.5824 - val_accuracy: 0.7159 - val_loss: 0.6925\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 309ms/step - accuracy: 0.7570 - loss: 0.5567 - val_accuracy: 0.7074 - val_loss: 0.6807\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 301ms/step - accuracy: 0.7860 - loss: 0.4949 - val_accuracy: 0.7056 - val_loss: 0.6813\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7196 - loss: 0.6570\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - accuracy: 0.5329 - loss: 1.0205 - val_accuracy: 0.5414 - val_loss: 0.9007\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.5717 - loss: 0.8870 - val_accuracy: 0.6201 - val_loss: 0.8509\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.6352 - loss: 0.8273 - val_accuracy: 0.6343 - val_loss: 0.8311\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.6423 - loss: 0.8102 - val_accuracy: 0.6543 - val_loss: 0.7982\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.6573 - loss: 0.7711 - val_accuracy: 0.6520 - val_loss: 0.7756\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6847 - loss: 0.7319 - val_accuracy: 0.6532 - val_loss: 0.7656\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.7108 - loss: 0.6851 - val_accuracy: 0.6743 - val_loss: 0.7268\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.7258 - loss: 0.6487 - val_accuracy: 0.6720 - val_loss: 0.7079\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.7532 - loss: 0.5920 - val_accuracy: 0.6908 - val_loss: 0.6825\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - accuracy: 0.7554 - loss: 0.5860 - val_accuracy: 0.6092 - val_loss: 0.8267\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.7445 - loss: 0.5811 - val_accuracy: 0.7091 - val_loss: 0.6901\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7730 - loss: 0.5134 - val_accuracy: 0.6669 - val_loss: 0.7213\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6972 - loss: 0.6677\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.4763 - loss: 1.0362 - val_accuracy: 0.5277 - val_loss: 0.9593\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.5449 - loss: 0.9439 - val_accuracy: 0.6281 - val_loss: 0.8513\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.6224 - loss: 0.8580 - val_accuracy: 0.6423 - val_loss: 0.8236\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.6448 - loss: 0.8215 - val_accuracy: 0.6201 - val_loss: 0.8348\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - accuracy: 0.6608 - loss: 0.7725 - val_accuracy: 0.6743 - val_loss: 0.7596\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6807 - loss: 0.7331 - val_accuracy: 0.6766 - val_loss: 0.7529\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.6920 - loss: 0.7206 - val_accuracy: 0.6988 - val_loss: 0.7097\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 137ms/step - accuracy: 0.7347 - loss: 0.6338 - val_accuracy: 0.6988 - val_loss: 0.6963\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.7497 - loss: 0.6050 - val_accuracy: 0.6931 - val_loss: 0.6800\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.7530 - loss: 0.5942 - val_accuracy: 0.6965 - val_loss: 0.6818\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7675 - loss: 0.5514 - val_accuracy: 0.7011 - val_loss: 0.6558\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7698 - loss: 0.5150 - val_accuracy: 0.6977 - val_loss: 0.6698\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - accuracy: 0.7752 - loss: 0.5183 - val_accuracy: 0.6914 - val_loss: 0.7518\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7963 - loss: 0.4896 - val_accuracy: 0.7085 - val_loss: 0.6650\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7108 - loss: 0.6324\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.5158 - loss: 1.0341 - val_accuracy: 0.5328 - val_loss: 0.8921\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.5778 - loss: 0.8687 - val_accuracy: 0.6207 - val_loss: 0.8643\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.6227 - loss: 0.8369 - val_accuracy: 0.6343 - val_loss: 0.8254\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6468 - loss: 0.8124 - val_accuracy: 0.6440 - val_loss: 0.8081\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.6586 - loss: 0.7891 - val_accuracy: 0.6537 - val_loss: 0.7890\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.6659 - loss: 0.7599 - val_accuracy: 0.6766 - val_loss: 0.7481\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.6892 - loss: 0.7243 - val_accuracy: 0.6640 - val_loss: 0.7499\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.7133 - loss: 0.6745 - val_accuracy: 0.6748 - val_loss: 0.7550\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.7262 - loss: 0.6417 - val_accuracy: 0.6760 - val_loss: 0.7018\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.7528 - loss: 0.5904 - val_accuracy: 0.7131 - val_loss: 0.6890\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - accuracy: 0.7643 - loss: 0.5633 - val_accuracy: 0.7182 - val_loss: 0.6656\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7786 - loss: 0.5167 - val_accuracy: 0.6868 - val_loss: 0.7211\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7817 - loss: 0.4872 - val_accuracy: 0.7034 - val_loss: 0.7149\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.7733 - loss: 0.5115 - val_accuracy: 0.7148 - val_loss: 0.7059\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7369 - loss: 0.6369\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.4744 - loss: 1.0352 - val_accuracy: 0.5265 - val_loss: 0.9401\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.5688 - loss: 0.9184 - val_accuracy: 0.6264 - val_loss: 0.8369\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6189 - loss: 0.8663 - val_accuracy: 0.6418 - val_loss: 0.8169\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - accuracy: 0.6479 - loss: 0.8229 - val_accuracy: 0.6458 - val_loss: 0.8097\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.6510 - loss: 0.8050 - val_accuracy: 0.6486 - val_loss: 0.7840\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6672 - loss: 0.7807 - val_accuracy: 0.6560 - val_loss: 0.7686\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - accuracy: 0.6764 - loss: 0.7444 - val_accuracy: 0.6760 - val_loss: 0.7286\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6927 - loss: 0.7079 - val_accuracy: 0.6606 - val_loss: 0.7425\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.6962 - loss: 0.6782 - val_accuracy: 0.6931 - val_loss: 0.6922\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7214 - loss: 0.6357 - val_accuracy: 0.7091 - val_loss: 0.6791\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.7365 - loss: 0.5994 - val_accuracy: 0.6959 - val_loss: 0.7012\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.7307 - loss: 0.5898 - val_accuracy: 0.7085 - val_loss: 0.6642\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.7498 - loss: 0.5414 - val_accuracy: 0.7062 - val_loss: 0.7009\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.7676 - loss: 0.5321 - val_accuracy: 0.7171 - val_loss: 0.6707\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7837 - loss: 0.4944 - val_accuracy: 0.7039 - val_loss: 0.7115\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7255 - loss: 0.6420\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 146ms/step - accuracy: 0.5049 - loss: 1.0094 - val_accuracy: 0.6189 - val_loss: 0.8719\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - accuracy: 0.6304 - loss: 0.8500 - val_accuracy: 0.6440 - val_loss: 0.8197\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - accuracy: 0.6358 - loss: 0.8096 - val_accuracy: 0.6560 - val_loss: 0.7836\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - accuracy: 0.6668 - loss: 0.7606 - val_accuracy: 0.6612 - val_loss: 0.7813\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.6828 - loss: 0.7348 - val_accuracy: 0.6908 - val_loss: 0.7068\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.7249 - loss: 0.6539 - val_accuracy: 0.6954 - val_loss: 0.6818\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - accuracy: 0.7162 - loss: 0.6406 - val_accuracy: 0.7142 - val_loss: 0.6544\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - accuracy: 0.7455 - loss: 0.5793 - val_accuracy: 0.6999 - val_loss: 0.6848\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 122ms/step - accuracy: 0.7599 - loss: 0.5476 - val_accuracy: 0.7114 - val_loss: 0.6826\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.7534 - loss: 0.5499 - val_accuracy: 0.6959 - val_loss: 0.7341\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.7217 - loss: 0.6342\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.4720 - loss: 1.0282 - val_accuracy: 0.5339 - val_loss: 0.9145\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.5885 - loss: 0.8811 - val_accuracy: 0.6207 - val_loss: 0.8537\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.6156 - loss: 0.8383 - val_accuracy: 0.6389 - val_loss: 0.8134\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 128ms/step - accuracy: 0.6440 - loss: 0.7937 - val_accuracy: 0.6594 - val_loss: 0.7867\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.6659 - loss: 0.7586 - val_accuracy: 0.6868 - val_loss: 0.7274\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.6963 - loss: 0.6944 - val_accuracy: 0.6783 - val_loss: 0.7505\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.7158 - loss: 0.6826 - val_accuracy: 0.6977 - val_loss: 0.6946\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.7274 - loss: 0.6423 - val_accuracy: 0.6891 - val_loss: 0.6867\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 171ms/step - accuracy: 0.7350 - loss: 0.6007 - val_accuracy: 0.7011 - val_loss: 0.6690\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 126ms/step - accuracy: 0.7612 - loss: 0.5611 - val_accuracy: 0.6942 - val_loss: 0.6798\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.7718 - loss: 0.5166 - val_accuracy: 0.6999 - val_loss: 0.6830\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.7672 - loss: 0.5277 - val_accuracy: 0.7034 - val_loss: 0.6816\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7138 - loss: 0.6535\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.5068 - loss: 1.0110 - val_accuracy: 0.5830 - val_loss: 0.8818\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.6106 - loss: 0.8624 - val_accuracy: 0.6326 - val_loss: 0.8307\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - accuracy: 0.6322 - loss: 0.8268 - val_accuracy: 0.6383 - val_loss: 0.8081\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.6522 - loss: 0.7824 - val_accuracy: 0.6612 - val_loss: 0.7778\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - accuracy: 0.6667 - loss: 0.7551 - val_accuracy: 0.6708 - val_loss: 0.7679\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - accuracy: 0.6783 - loss: 0.7378 - val_accuracy: 0.6754 - val_loss: 0.7577\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.7173 - loss: 0.6571 - val_accuracy: 0.7096 - val_loss: 0.6838\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.7419 - loss: 0.6226 - val_accuracy: 0.7062 - val_loss: 0.6720\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 0.7534 - loss: 0.5703 - val_accuracy: 0.7056 - val_loss: 0.7205\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.7706 - loss: 0.5371 - val_accuracy: 0.7022 - val_loss: 0.6753\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.7839 - loss: 0.4894 - val_accuracy: 0.7028 - val_loss: 0.6537\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.7929 - loss: 0.4848 - val_accuracy: 0.6828 - val_loss: 0.6736\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.8132 - loss: 0.4355 - val_accuracy: 0.7051 - val_loss: 0.6986\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 126ms/step - accuracy: 0.8126 - loss: 0.4320 - val_accuracy: 0.7091 - val_loss: 0.7413\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7126 - loss: 0.6432\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step - accuracy: 0.4989 - loss: 1.0270 - val_accuracy: 0.5739 - val_loss: 0.8825\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - accuracy: 0.6038 - loss: 0.8773 - val_accuracy: 0.6303 - val_loss: 0.8183\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.6306 - loss: 0.8233 - val_accuracy: 0.6492 - val_loss: 0.8028\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - accuracy: 0.6323 - loss: 0.8336 - val_accuracy: 0.6520 - val_loss: 0.7707\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.6669 - loss: 0.7599 - val_accuracy: 0.6788 - val_loss: 0.7435\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - accuracy: 0.6876 - loss: 0.7282 - val_accuracy: 0.6731 - val_loss: 0.7372\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.7200 - loss: 0.6682 - val_accuracy: 0.6977 - val_loss: 0.6940\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.7382 - loss: 0.6171 - val_accuracy: 0.6902 - val_loss: 0.6876\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - accuracy: 0.7500 - loss: 0.5991 - val_accuracy: 0.7045 - val_loss: 0.7293\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.7612 - loss: 0.5712 - val_accuracy: 0.7045 - val_loss: 0.6589\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 173ms/step - accuracy: 0.7790 - loss: 0.5292 - val_accuracy: 0.7114 - val_loss: 0.6991\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.7806 - loss: 0.4870 - val_accuracy: 0.7017 - val_loss: 0.6627\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - accuracy: 0.7937 - loss: 0.4858 - val_accuracy: 0.6942 - val_loss: 0.7414\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.7169 - loss: 0.6406\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 305ms/step - accuracy: 0.5269 - loss: 0.9949 - val_accuracy: 0.5944 - val_loss: 0.8916\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 0.6204 - loss: 0.8477 - val_accuracy: 0.6189 - val_loss: 0.8427\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 311ms/step - accuracy: 0.6364 - loss: 0.8134 - val_accuracy: 0.6577 - val_loss: 0.7632\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 303ms/step - accuracy: 0.6694 - loss: 0.7456 - val_accuracy: 0.7028 - val_loss: 0.7226\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 305ms/step - accuracy: 0.7071 - loss: 0.6842 - val_accuracy: 0.6908 - val_loss: 0.6950\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 312ms/step - accuracy: 0.7103 - loss: 0.6535 - val_accuracy: 0.6971 - val_loss: 0.6871\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 309ms/step - accuracy: 0.7292 - loss: 0.6204 - val_accuracy: 0.6743 - val_loss: 0.7377\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 305ms/step - accuracy: 0.7454 - loss: 0.5822 - val_accuracy: 0.7102 - val_loss: 0.6799\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 311ms/step - accuracy: 0.7675 - loss: 0.5458 - val_accuracy: 0.7136 - val_loss: 0.6589\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 314ms/step - accuracy: 0.7728 - loss: 0.5241 - val_accuracy: 0.7159 - val_loss: 0.6963\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 292ms/step - accuracy: 0.7764 - loss: 0.4993 - val_accuracy: 0.6988 - val_loss: 0.6874\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 0.7992 - loss: 0.4723 - val_accuracy: 0.7091 - val_loss: 0.6629\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.7117 - loss: 0.6420\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.5234 - loss: 0.9853 - val_accuracy: 0.6041 - val_loss: 0.8791\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 293ms/step - accuracy: 0.6404 - loss: 0.8469 - val_accuracy: 0.6469 - val_loss: 0.8193\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.6467 - loss: 0.7997 - val_accuracy: 0.6264 - val_loss: 0.8869\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 0.6716 - loss: 0.7851 - val_accuracy: 0.6566 - val_loss: 0.7729\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 312ms/step - accuracy: 0.6953 - loss: 0.7213 - val_accuracy: 0.6771 - val_loss: 0.7468\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 302ms/step - accuracy: 0.7081 - loss: 0.7152 - val_accuracy: 0.6908 - val_loss: 0.7038\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 312ms/step - accuracy: 0.7376 - loss: 0.6406 - val_accuracy: 0.6891 - val_loss: 0.6993\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 324ms/step - accuracy: 0.7451 - loss: 0.6134 - val_accuracy: 0.7034 - val_loss: 0.6694\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 358ms/step - accuracy: 0.7597 - loss: 0.5632 - val_accuracy: 0.6908 - val_loss: 0.7146\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 322ms/step - accuracy: 0.7500 - loss: 0.5747 - val_accuracy: 0.7085 - val_loss: 0.6592\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 337ms/step - accuracy: 0.7788 - loss: 0.5147 - val_accuracy: 0.6982 - val_loss: 0.7203\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 285ms/step - accuracy: 0.7762 - loss: 0.5120 - val_accuracy: 0.6800 - val_loss: 0.7061\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 319ms/step - accuracy: 0.7819 - loss: 0.4825 - val_accuracy: 0.7136 - val_loss: 0.6764\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.7099 - loss: 0.6450\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 367ms/step - accuracy: 0.5265 - loss: 0.9743 - val_accuracy: 0.6064 - val_loss: 0.8559\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 317ms/step - accuracy: 0.6237 - loss: 0.8481 - val_accuracy: 0.6372 - val_loss: 0.8126\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 321ms/step - accuracy: 0.6475 - loss: 0.8147 - val_accuracy: 0.6361 - val_loss: 0.8325\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 325ms/step - accuracy: 0.6653 - loss: 0.7618 - val_accuracy: 0.6743 - val_loss: 0.7500\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 314ms/step - accuracy: 0.6828 - loss: 0.7199 - val_accuracy: 0.6788 - val_loss: 0.7252\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 281ms/step - accuracy: 0.7000 - loss: 0.6706 - val_accuracy: 0.7136 - val_loss: 0.6869\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 315ms/step - accuracy: 0.7365 - loss: 0.6497 - val_accuracy: 0.6452 - val_loss: 0.7464\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 303ms/step - accuracy: 0.7253 - loss: 0.6271 - val_accuracy: 0.7176 - val_loss: 0.6929\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.7567 - loss: 0.5728 - val_accuracy: 0.7108 - val_loss: 0.6451\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 321ms/step - accuracy: 0.7793 - loss: 0.5205 - val_accuracy: 0.7068 - val_loss: 0.6710\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 309ms/step - accuracy: 0.7810 - loss: 0.5148 - val_accuracy: 0.7011 - val_loss: 0.7111\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 297ms/step - accuracy: 0.7941 - loss: 0.4635 - val_accuracy: 0.6994 - val_loss: 0.6774\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.7227 - loss: 0.6292\n",
            "Training with combination: vector_size=300, window=10, negative=20, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 311ms/step - accuracy: 0.5276 - loss: 0.9943 - val_accuracy: 0.6241 - val_loss: 0.8414\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 316ms/step - accuracy: 0.6094 - loss: 0.8665 - val_accuracy: 0.6463 - val_loss: 0.8231\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 308ms/step - accuracy: 0.6336 - loss: 0.8237 - val_accuracy: 0.6549 - val_loss: 0.7998\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 283ms/step - accuracy: 0.6627 - loss: 0.7718 - val_accuracy: 0.6771 - val_loss: 0.7601\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 305ms/step - accuracy: 0.6967 - loss: 0.7190 - val_accuracy: 0.6959 - val_loss: 0.7140\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 278ms/step - accuracy: 0.6946 - loss: 0.6959 - val_accuracy: 0.6937 - val_loss: 0.6949\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 316ms/step - accuracy: 0.7319 - loss: 0.6478 - val_accuracy: 0.7102 - val_loss: 0.6778\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 295ms/step - accuracy: 0.7451 - loss: 0.6085 - val_accuracy: 0.7005 - val_loss: 0.6751\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 277ms/step - accuracy: 0.7638 - loss: 0.5688 - val_accuracy: 0.6880 - val_loss: 0.6734\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 311ms/step - accuracy: 0.7743 - loss: 0.5278 - val_accuracy: 0.7051 - val_loss: 0.6630\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 298ms/step - accuracy: 0.7810 - loss: 0.5099 - val_accuracy: 0.7131 - val_loss: 0.6424\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 318ms/step - accuracy: 0.7927 - loss: 0.4768 - val_accuracy: 0.7045 - val_loss: 0.6663\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 296ms/step - accuracy: 0.8125 - loss: 0.4402 - val_accuracy: 0.7108 - val_loss: 0.6714\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 310ms/step - accuracy: 0.8001 - loss: 0.4388 - val_accuracy: 0.6503 - val_loss: 0.8182\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.7292 - loss: 0.6252\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - accuracy: 0.5149 - loss: 1.0238 - val_accuracy: 0.5482 - val_loss: 0.9173\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5846 - loss: 0.8658 - val_accuracy: 0.6167 - val_loss: 0.8378\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6326 - loss: 0.8209 - val_accuracy: 0.6224 - val_loss: 0.8038\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.6653 - loss: 0.7518 - val_accuracy: 0.6760 - val_loss: 0.7446\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6771 - loss: 0.7267 - val_accuracy: 0.6982 - val_loss: 0.7032\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.7237 - loss: 0.6504 - val_accuracy: 0.7091 - val_loss: 0.6905\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.7289 - loss: 0.6343 - val_accuracy: 0.6805 - val_loss: 0.7253\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7476 - loss: 0.5969 - val_accuracy: 0.7136 - val_loss: 0.6945\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.7675 - loss: 0.5433 - val_accuracy: 0.7096 - val_loss: 0.6648\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - accuracy: 0.7743 - loss: 0.5333 - val_accuracy: 0.7148 - val_loss: 0.6746\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7819 - loss: 0.4970 - val_accuracy: 0.7222 - val_loss: 0.6667\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.7911 - loss: 0.4699 - val_accuracy: 0.7119 - val_loss: 0.6785\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7224 - loss: 0.6461\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.4983 - loss: 1.0278 - val_accuracy: 0.5282 - val_loss: 0.9395\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - accuracy: 0.5575 - loss: 0.9197 - val_accuracy: 0.6218 - val_loss: 0.8450\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6196 - loss: 0.8326 - val_accuracy: 0.6235 - val_loss: 0.8406\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.6511 - loss: 0.7952 - val_accuracy: 0.6577 - val_loss: 0.7865\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.6670 - loss: 0.7697 - val_accuracy: 0.6714 - val_loss: 0.7582\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.7112 - loss: 0.6985 - val_accuracy: 0.7056 - val_loss: 0.7015\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.7187 - loss: 0.6367 - val_accuracy: 0.7022 - val_loss: 0.6864\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - accuracy: 0.7329 - loss: 0.6165 - val_accuracy: 0.7102 - val_loss: 0.6772\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7503 - loss: 0.5834 - val_accuracy: 0.7039 - val_loss: 0.6907\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7805 - loss: 0.5242 - val_accuracy: 0.7233 - val_loss: 0.7056\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - accuracy: 0.7854 - loss: 0.5045 - val_accuracy: 0.7136 - val_loss: 0.6714\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.7859 - loss: 0.4932 - val_accuracy: 0.6948 - val_loss: 0.7166\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.8068 - loss: 0.4469 - val_accuracy: 0.7216 - val_loss: 0.7356\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8218 - loss: 0.4148 - val_accuracy: 0.6954 - val_loss: 0.7460\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7301 - loss: 0.6434\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - accuracy: 0.4591 - loss: 1.0569 - val_accuracy: 0.5288 - val_loss: 0.9494\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5715 - loss: 0.8902 - val_accuracy: 0.6189 - val_loss: 0.8492\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.6449 - loss: 0.8376 - val_accuracy: 0.6537 - val_loss: 0.7947\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.6447 - loss: 0.7925 - val_accuracy: 0.6691 - val_loss: 0.7598\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6687 - loss: 0.7506 - val_accuracy: 0.6834 - val_loss: 0.7393\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.6969 - loss: 0.7065 - val_accuracy: 0.7034 - val_loss: 0.7179\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.7234 - loss: 0.6610 - val_accuracy: 0.7125 - val_loss: 0.6916\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.7569 - loss: 0.5842 - val_accuracy: 0.6954 - val_loss: 0.7080\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.7616 - loss: 0.5826 - val_accuracy: 0.6908 - val_loss: 0.7088\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.7790 - loss: 0.5375 - val_accuracy: 0.7039 - val_loss: 0.7021\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7157 - loss: 0.6657\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 103ms/step - accuracy: 0.4797 - loss: 1.0298 - val_accuracy: 0.5362 - val_loss: 0.9421\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.5631 - loss: 0.9118 - val_accuracy: 0.6258 - val_loss: 0.8419\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6239 - loss: 0.8443 - val_accuracy: 0.6383 - val_loss: 0.8222\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.6370 - loss: 0.8116 - val_accuracy: 0.6458 - val_loss: 0.8085\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.6626 - loss: 0.7949 - val_accuracy: 0.6606 - val_loss: 0.7922\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.6646 - loss: 0.7565 - val_accuracy: 0.6646 - val_loss: 0.7771\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.6782 - loss: 0.7255 - val_accuracy: 0.6834 - val_loss: 0.7444\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7176 - loss: 0.6684 - val_accuracy: 0.6994 - val_loss: 0.7150\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.7376 - loss: 0.6385 - val_accuracy: 0.7017 - val_loss: 0.6900\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.7522 - loss: 0.5957 - val_accuracy: 0.7068 - val_loss: 0.7010\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.7502 - loss: 0.5698 - val_accuracy: 0.7262 - val_loss: 0.6976\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.7912 - loss: 0.4939 - val_accuracy: 0.7108 - val_loss: 0.6910\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7053 - loss: 0.6765\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.5132 - loss: 1.0069 - val_accuracy: 0.6189 - val_loss: 0.8575\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.6098 - loss: 0.8476 - val_accuracy: 0.6361 - val_loss: 0.8101\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.6602 - loss: 0.7861 - val_accuracy: 0.6623 - val_loss: 0.7743\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.6729 - loss: 0.7417 - val_accuracy: 0.6623 - val_loss: 0.7497\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.7011 - loss: 0.6882 - val_accuracy: 0.6914 - val_loss: 0.7075\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - accuracy: 0.7258 - loss: 0.6643 - val_accuracy: 0.6549 - val_loss: 0.8118\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - accuracy: 0.7240 - loss: 0.6633 - val_accuracy: 0.6999 - val_loss: 0.6967\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.7609 - loss: 0.5678 - val_accuracy: 0.6874 - val_loss: 0.6938\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - accuracy: 0.7600 - loss: 0.5672 - val_accuracy: 0.7096 - val_loss: 0.6572\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 186ms/step - accuracy: 0.7723 - loss: 0.5353 - val_accuracy: 0.7210 - val_loss: 0.6580\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 127ms/step - accuracy: 0.7860 - loss: 0.5051 - val_accuracy: 0.7114 - val_loss: 0.6716\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.7939 - loss: 0.4556 - val_accuracy: 0.6982 - val_loss: 0.6680\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7172 - loss: 0.6445\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.5344 - loss: 1.0045 - val_accuracy: 0.5425 - val_loss: 0.9451\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.5814 - loss: 0.8831 - val_accuracy: 0.6281 - val_loss: 0.8170\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.6483 - loss: 0.8040 - val_accuracy: 0.6566 - val_loss: 0.7788\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - accuracy: 0.6818 - loss: 0.7483 - val_accuracy: 0.6440 - val_loss: 0.7692\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.6962 - loss: 0.6991 - val_accuracy: 0.6971 - val_loss: 0.6931\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.7315 - loss: 0.6377 - val_accuracy: 0.7005 - val_loss: 0.6913\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.7455 - loss: 0.5869 - val_accuracy: 0.7034 - val_loss: 0.6819\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 175ms/step - accuracy: 0.7602 - loss: 0.5717 - val_accuracy: 0.7051 - val_loss: 0.7084\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.7615 - loss: 0.5654 - val_accuracy: 0.7199 - val_loss: 0.6513\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.7877 - loss: 0.5095 - val_accuracy: 0.7142 - val_loss: 0.6771\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.7800 - loss: 0.4903 - val_accuracy: 0.7011 - val_loss: 0.7245\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.7916 - loss: 0.4624 - val_accuracy: 0.7114 - val_loss: 0.7118\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7274 - loss: 0.6432\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.4835 - loss: 1.0305 - val_accuracy: 0.6275 - val_loss: 0.8620\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 127ms/step - accuracy: 0.6378 - loss: 0.8387 - val_accuracy: 0.6366 - val_loss: 0.8222\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.6506 - loss: 0.7959 - val_accuracy: 0.6583 - val_loss: 0.7761\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 147ms/step - accuracy: 0.6726 - loss: 0.7351 - val_accuracy: 0.6954 - val_loss: 0.7151\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.7236 - loss: 0.6618 - val_accuracy: 0.6965 - val_loss: 0.7345\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.7188 - loss: 0.6567 - val_accuracy: 0.7056 - val_loss: 0.6669\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.7488 - loss: 0.5829 - val_accuracy: 0.6771 - val_loss: 0.6868\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.7598 - loss: 0.5622 - val_accuracy: 0.7153 - val_loss: 0.6551\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - accuracy: 0.7660 - loss: 0.5417 - val_accuracy: 0.6954 - val_loss: 0.6897\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.7810 - loss: 0.5085 - val_accuracy: 0.7034 - val_loss: 0.6643\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.7958 - loss: 0.4823 - val_accuracy: 0.7114 - val_loss: 0.6607\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7311 - loss: 0.6302\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.5008 - loss: 1.0217 - val_accuracy: 0.5836 - val_loss: 0.8756\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 158ms/step - accuracy: 0.6039 - loss: 0.8716 - val_accuracy: 0.6366 - val_loss: 0.8385\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.6468 - loss: 0.8105 - val_accuracy: 0.6515 - val_loss: 0.7981\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.6566 - loss: 0.7890 - val_accuracy: 0.6634 - val_loss: 0.7605\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.6888 - loss: 0.7218 - val_accuracy: 0.6497 - val_loss: 0.7510\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - accuracy: 0.6990 - loss: 0.6927 - val_accuracy: 0.6845 - val_loss: 0.7101\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.7261 - loss: 0.6389 - val_accuracy: 0.6920 - val_loss: 0.7606\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - accuracy: 0.7227 - loss: 0.6323 - val_accuracy: 0.7017 - val_loss: 0.6988\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.7707 - loss: 0.5458 - val_accuracy: 0.6914 - val_loss: 0.6649\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 173ms/step - accuracy: 0.7799 - loss: 0.5139 - val_accuracy: 0.7199 - val_loss: 0.6741\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 126ms/step - accuracy: 0.7863 - loss: 0.4993 - val_accuracy: 0.6783 - val_loss: 0.7378\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - accuracy: 0.7953 - loss: 0.4877 - val_accuracy: 0.7011 - val_loss: 0.7113\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7029 - loss: 0.6402\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 296ms/step - accuracy: 0.5240 - loss: 0.9873 - val_accuracy: 0.6315 - val_loss: 0.8260\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 289ms/step - accuracy: 0.6450 - loss: 0.8191 - val_accuracy: 0.6566 - val_loss: 0.7899\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 319ms/step - accuracy: 0.6709 - loss: 0.7493 - val_accuracy: 0.6669 - val_loss: 0.7733\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 314ms/step - accuracy: 0.7041 - loss: 0.7071 - val_accuracy: 0.7034 - val_loss: 0.6986\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 309ms/step - accuracy: 0.7284 - loss: 0.6467 - val_accuracy: 0.6925 - val_loss: 0.6804\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 316ms/step - accuracy: 0.7465 - loss: 0.6035 - val_accuracy: 0.6977 - val_loss: 0.6743\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 0.7390 - loss: 0.5710 - val_accuracy: 0.7114 - val_loss: 0.6593\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 322ms/step - accuracy: 0.7781 - loss: 0.5337 - val_accuracy: 0.7034 - val_loss: 0.6744\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 298ms/step - accuracy: 0.7733 - loss: 0.5088 - val_accuracy: 0.7034 - val_loss: 0.6900\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 289ms/step - accuracy: 0.7731 - loss: 0.4982 - val_accuracy: 0.6777 - val_loss: 0.6897\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7229 - loss: 0.6468\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 323ms/step - accuracy: 0.5000 - loss: 1.0114 - val_accuracy: 0.5048 - val_loss: 0.9819\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 404ms/step - accuracy: 0.6008 - loss: 0.8828 - val_accuracy: 0.6343 - val_loss: 0.8539\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 319ms/step - accuracy: 0.6587 - loss: 0.7970 - val_accuracy: 0.6634 - val_loss: 0.7770\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 317ms/step - accuracy: 0.6935 - loss: 0.7237 - val_accuracy: 0.6463 - val_loss: 0.7663\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 307ms/step - accuracy: 0.7027 - loss: 0.7036 - val_accuracy: 0.6959 - val_loss: 0.7199\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 319ms/step - accuracy: 0.7311 - loss: 0.6321 - val_accuracy: 0.7028 - val_loss: 0.6617\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 0.7372 - loss: 0.6136 - val_accuracy: 0.7017 - val_loss: 0.6968\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 312ms/step - accuracy: 0.7438 - loss: 0.5958 - val_accuracy: 0.7102 - val_loss: 0.6686\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 313ms/step - accuracy: 0.7823 - loss: 0.5178 - val_accuracy: 0.7114 - val_loss: 0.6718\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.7097 - loss: 0.6426\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 325ms/step - accuracy: 0.5480 - loss: 0.9900 - val_accuracy: 0.6400 - val_loss: 0.8595\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.6324 - loss: 0.8308 - val_accuracy: 0.6246 - val_loss: 0.8238\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 0.6703 - loss: 0.7900 - val_accuracy: 0.6902 - val_loss: 0.7248\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 315ms/step - accuracy: 0.6824 - loss: 0.7306 - val_accuracy: 0.6863 - val_loss: 0.7107\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.7329 - loss: 0.6424 - val_accuracy: 0.6897 - val_loss: 0.6938\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 0.7304 - loss: 0.6126 - val_accuracy: 0.6999 - val_loss: 0.6774\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 287ms/step - accuracy: 0.7621 - loss: 0.5762 - val_accuracy: 0.7142 - val_loss: 0.6697\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 312ms/step - accuracy: 0.7651 - loss: 0.5358 - val_accuracy: 0.7245 - val_loss: 0.6699\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 311ms/step - accuracy: 0.7797 - loss: 0.5054 - val_accuracy: 0.6954 - val_loss: 0.6766\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 281ms/step - accuracy: 0.7860 - loss: 0.4824 - val_accuracy: 0.7017 - val_loss: 0.6536\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 317ms/step - accuracy: 0.8016 - loss: 0.4383 - val_accuracy: 0.6788 - val_loss: 0.7491\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.8120 - loss: 0.4412 - val_accuracy: 0.7228 - val_loss: 0.6747\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 286ms/step - accuracy: 0.8174 - loss: 0.4038 - val_accuracy: 0.7159 - val_loss: 0.7339\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.7188 - loss: 0.6153\n",
            "Training with combination: vector_size=300, window=25, negative=10, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 387ms/step - accuracy: 0.5252 - loss: 0.9850 - val_accuracy: 0.6189 - val_loss: 0.8501\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 389ms/step - accuracy: 0.6255 - loss: 0.8434 - val_accuracy: 0.6383 - val_loss: 0.8664\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 430ms/step - accuracy: 0.6589 - loss: 0.8010 - val_accuracy: 0.6543 - val_loss: 0.7975\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 380ms/step - accuracy: 0.6835 - loss: 0.7378 - val_accuracy: 0.6748 - val_loss: 0.7873\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 384ms/step - accuracy: 0.7018 - loss: 0.6963 - val_accuracy: 0.6925 - val_loss: 0.7004\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 414ms/step - accuracy: 0.7166 - loss: 0.6562 - val_accuracy: 0.7165 - val_loss: 0.6736\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 382ms/step - accuracy: 0.7270 - loss: 0.6197 - val_accuracy: 0.6988 - val_loss: 0.6852\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 345ms/step - accuracy: 0.7376 - loss: 0.6025 - val_accuracy: 0.6988 - val_loss: 0.6825\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 317ms/step - accuracy: 0.7614 - loss: 0.5489 - val_accuracy: 0.6937 - val_loss: 0.6854\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.7188 - loss: 0.6579\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.4816 - loss: 1.0380 - val_accuracy: 0.5317 - val_loss: 0.9360\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.5862 - loss: 0.8915 - val_accuracy: 0.6281 - val_loss: 0.8582\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.6360 - loss: 0.8356 - val_accuracy: 0.6452 - val_loss: 0.8236\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6543 - loss: 0.7882 - val_accuracy: 0.6731 - val_loss: 0.7550\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - accuracy: 0.6958 - loss: 0.7169 - val_accuracy: 0.6902 - val_loss: 0.7153\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.7134 - loss: 0.6520 - val_accuracy: 0.7034 - val_loss: 0.6826\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.7403 - loss: 0.6043 - val_accuracy: 0.7131 - val_loss: 0.6901\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.7606 - loss: 0.5503 - val_accuracy: 0.6589 - val_loss: 0.7458\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - accuracy: 0.7567 - loss: 0.5634 - val_accuracy: 0.7182 - val_loss: 0.6748\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.7744 - loss: 0.5280 - val_accuracy: 0.6971 - val_loss: 0.7034\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.8114 - loss: 0.4646 - val_accuracy: 0.6954 - val_loss: 0.7064\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.8102 - loss: 0.4511 - val_accuracy: 0.7165 - val_loss: 0.7199\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7319 - loss: 0.6409\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=64, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.5502 - loss: 1.0269 - val_accuracy: 0.5294 - val_loss: 0.9616\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.5619 - loss: 0.9234 - val_accuracy: 0.6241 - val_loss: 0.8464\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - accuracy: 0.6224 - loss: 0.8470 - val_accuracy: 0.6366 - val_loss: 0.8288\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.6488 - loss: 0.8159 - val_accuracy: 0.6423 - val_loss: 0.8283\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.6560 - loss: 0.8027 - val_accuracy: 0.6110 - val_loss: 0.8268\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.6426 - loss: 0.7830 - val_accuracy: 0.6720 - val_loss: 0.7415\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.6989 - loss: 0.7019 - val_accuracy: 0.6857 - val_loss: 0.7173\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7400 - loss: 0.6500 - val_accuracy: 0.6999 - val_loss: 0.6947\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7283 - loss: 0.6184 - val_accuracy: 0.6971 - val_loss: 0.7020\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.7707 - loss: 0.5532 - val_accuracy: 0.6874 - val_loss: 0.7049\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7637 - loss: 0.5548 - val_accuracy: 0.7068 - val_loss: 0.7255\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7082 - loss: 0.6876\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.4922 - loss: 1.0333 - val_accuracy: 0.5265 - val_loss: 0.9334\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.5529 - loss: 0.8986 - val_accuracy: 0.6189 - val_loss: 0.8487\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6266 - loss: 0.8284 - val_accuracy: 0.6269 - val_loss: 0.8340\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.6442 - loss: 0.8122 - val_accuracy: 0.6372 - val_loss: 0.8110\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.6629 - loss: 0.7799 - val_accuracy: 0.6623 - val_loss: 0.7969\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.6950 - loss: 0.7308 - val_accuracy: 0.6720 - val_loss: 0.7245\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.6989 - loss: 0.6842 - val_accuracy: 0.6634 - val_loss: 0.7218\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.7276 - loss: 0.6423 - val_accuracy: 0.6954 - val_loss: 0.6914\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.7435 - loss: 0.6008 - val_accuracy: 0.7051 - val_loss: 0.6772\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7654 - loss: 0.5513 - val_accuracy: 0.6908 - val_loss: 0.6854\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.7600 - loss: 0.5512 - val_accuracy: 0.6703 - val_loss: 0.7273\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.7887 - loss: 0.5060 - val_accuracy: 0.7096 - val_loss: 0.6731\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.8087 - loss: 0.4436 - val_accuracy: 0.7114 - val_loss: 0.6988\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8240 - loss: 0.4152 - val_accuracy: 0.7005 - val_loss: 0.7038\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.8136 - loss: 0.4344 - val_accuracy: 0.7131 - val_loss: 0.7615\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7149 - loss: 0.6568\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=64, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.5070 - loss: 1.0375 - val_accuracy: 0.5351 - val_loss: 0.9244\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - accuracy: 0.5711 - loss: 0.9100 - val_accuracy: 0.6212 - val_loss: 0.8527\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.6444 - loss: 0.8256 - val_accuracy: 0.6303 - val_loss: 0.8169\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6608 - loss: 0.7819 - val_accuracy: 0.6412 - val_loss: 0.8000\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.6712 - loss: 0.7483 - val_accuracy: 0.6703 - val_loss: 0.7500\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.7022 - loss: 0.7065 - val_accuracy: 0.6714 - val_loss: 0.7310\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.7015 - loss: 0.6720 - val_accuracy: 0.7096 - val_loss: 0.6926\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.7377 - loss: 0.6215 - val_accuracy: 0.6863 - val_loss: 0.6925\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.7555 - loss: 0.5826 - val_accuracy: 0.6845 - val_loss: 0.7171\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.7651 - loss: 0.5442 - val_accuracy: 0.7114 - val_loss: 0.7003\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.7857 - loss: 0.5183 - val_accuracy: 0.6880 - val_loss: 0.6857\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7937 - loss: 0.4895 - val_accuracy: 0.7079 - val_loss: 0.7284\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.8028 - loss: 0.4538 - val_accuracy: 0.7096 - val_loss: 0.7067\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.7954 - loss: 0.4553 - val_accuracy: 0.7096 - val_loss: 0.7374\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6990 - loss: 0.6603\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 135ms/step - accuracy: 0.5290 - loss: 1.0064 - val_accuracy: 0.6121 - val_loss: 0.8703\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.6340 - loss: 0.8549 - val_accuracy: 0.6520 - val_loss: 0.7894\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - accuracy: 0.6533 - loss: 0.7871 - val_accuracy: 0.6669 - val_loss: 0.7509\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.6953 - loss: 0.7155 - val_accuracy: 0.6931 - val_loss: 0.6997\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 139ms/step - accuracy: 0.7258 - loss: 0.6474 - val_accuracy: 0.7039 - val_loss: 0.6948\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - accuracy: 0.7468 - loss: 0.6064 - val_accuracy: 0.6857 - val_loss: 0.6906\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.7401 - loss: 0.5934 - val_accuracy: 0.7028 - val_loss: 0.6931\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - accuracy: 0.7651 - loss: 0.5494 - val_accuracy: 0.7205 - val_loss: 0.6400\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.7746 - loss: 0.5129 - val_accuracy: 0.6817 - val_loss: 0.7064\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.7678 - loss: 0.5232 - val_accuracy: 0.7199 - val_loss: 0.6814\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.8044 - loss: 0.4514 - val_accuracy: 0.7188 - val_loss: 0.7076\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7274 - loss: 0.6203\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=128, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - accuracy: 0.5189 - loss: 1.0163 - val_accuracy: 0.5750 - val_loss: 0.9039\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.6059 - loss: 0.8805 - val_accuracy: 0.6343 - val_loss: 0.8206\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - accuracy: 0.6457 - loss: 0.8110 - val_accuracy: 0.6412 - val_loss: 0.8068\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.6626 - loss: 0.7723 - val_accuracy: 0.6754 - val_loss: 0.7407\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.6653 - loss: 0.7457 - val_accuracy: 0.6104 - val_loss: 0.8081\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.6767 - loss: 0.7186 - val_accuracy: 0.6988 - val_loss: 0.6986\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.7366 - loss: 0.6403 - val_accuracy: 0.6942 - val_loss: 0.6809\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.7495 - loss: 0.5813 - val_accuracy: 0.7159 - val_loss: 0.6737\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.7576 - loss: 0.5619 - val_accuracy: 0.7056 - val_loss: 0.6896\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - accuracy: 0.7852 - loss: 0.5286 - val_accuracy: 0.7222 - val_loss: 0.6783\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - accuracy: 0.7886 - loss: 0.4836 - val_accuracy: 0.7096 - val_loss: 0.7092\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7278 - loss: 0.6504\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 151ms/step - accuracy: 0.5233 - loss: 1.0019 - val_accuracy: 0.6167 - val_loss: 0.8677\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - accuracy: 0.6100 - loss: 0.8479 - val_accuracy: 0.6366 - val_loss: 0.8012\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.6384 - loss: 0.8055 - val_accuracy: 0.6349 - val_loss: 0.7846\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.6656 - loss: 0.7360 - val_accuracy: 0.6937 - val_loss: 0.7170\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 167ms/step - accuracy: 0.7159 - loss: 0.6715 - val_accuracy: 0.6469 - val_loss: 0.7625\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 130ms/step - accuracy: 0.7089 - loss: 0.6688 - val_accuracy: 0.7056 - val_loss: 0.6850\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.7464 - loss: 0.5794 - val_accuracy: 0.6908 - val_loss: 0.6870\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.7756 - loss: 0.5576 - val_accuracy: 0.6743 - val_loss: 0.7325\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 152ms/step - accuracy: 0.7666 - loss: 0.5426 - val_accuracy: 0.7005 - val_loss: 0.6753\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - accuracy: 0.7867 - loss: 0.4906 - val_accuracy: 0.6834 - val_loss: 0.7272\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 127ms/step - accuracy: 0.7938 - loss: 0.4801 - val_accuracy: 0.6868 - val_loss: 0.7036\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.8037 - loss: 0.4303 - val_accuracy: 0.7051 - val_loss: 0.7267\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7187 - loss: 0.6596\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=128, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 168ms/step - accuracy: 0.5171 - loss: 1.0142 - val_accuracy: 0.5950 - val_loss: 0.8791\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 126ms/step - accuracy: 0.6223 - loss: 0.8679 - val_accuracy: 0.6246 - val_loss: 0.8506\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.6277 - loss: 0.8402 - val_accuracy: 0.6446 - val_loss: 0.8171\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.6583 - loss: 0.7822 - val_accuracy: 0.6560 - val_loss: 0.7706\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - accuracy: 0.6839 - loss: 0.7398 - val_accuracy: 0.6783 - val_loss: 0.7320\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.7130 - loss: 0.6682 - val_accuracy: 0.6977 - val_loss: 0.6875\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.7319 - loss: 0.6252 - val_accuracy: 0.7102 - val_loss: 0.6924\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.7488 - loss: 0.5861 - val_accuracy: 0.6999 - val_loss: 0.6871\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - accuracy: 0.7666 - loss: 0.5665 - val_accuracy: 0.7074 - val_loss: 0.7112\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.7663 - loss: 0.5273 - val_accuracy: 0.7125 - val_loss: 0.6634\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.7805 - loss: 0.5160 - val_accuracy: 0.7085 - val_loss: 0.6490\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.7854 - loss: 0.5020 - val_accuracy: 0.7205 - val_loss: 0.6941\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 151ms/step - accuracy: 0.8150 - loss: 0.4540 - val_accuracy: 0.7131 - val_loss: 0.6918\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.8088 - loss: 0.4437 - val_accuracy: 0.7239 - val_loss: 0.6761\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7187 - loss: 0.6340\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 313ms/step - accuracy: 0.5235 - loss: 0.9665 - val_accuracy: 0.6058 - val_loss: 0.8535\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 296ms/step - accuracy: 0.6289 - loss: 0.8263 - val_accuracy: 0.6400 - val_loss: 0.8243\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 273ms/step - accuracy: 0.6454 - loss: 0.7963 - val_accuracy: 0.6731 - val_loss: 0.7728\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 314ms/step - accuracy: 0.6810 - loss: 0.7240 - val_accuracy: 0.6891 - val_loss: 0.7265\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 305ms/step - accuracy: 0.7142 - loss: 0.6799 - val_accuracy: 0.6885 - val_loss: 0.7078\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 273ms/step - accuracy: 0.7449 - loss: 0.6201 - val_accuracy: 0.7051 - val_loss: 0.6756\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 300ms/step - accuracy: 0.7456 - loss: 0.6045 - val_accuracy: 0.6669 - val_loss: 0.7161\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 312ms/step - accuracy: 0.7634 - loss: 0.5469 - val_accuracy: 0.7136 - val_loss: 0.6777\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 308ms/step - accuracy: 0.7702 - loss: 0.5211 - val_accuracy: 0.6748 - val_loss: 0.7068\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.7111 - loss: 0.6549\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=256, dropout_rate_lstm=0.4, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 314ms/step - accuracy: 0.5052 - loss: 1.0017 - val_accuracy: 0.6052 - val_loss: 0.8568\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.6246 - loss: 0.8518 - val_accuracy: 0.6235 - val_loss: 0.8577\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 295ms/step - accuracy: 0.6314 - loss: 0.8314 - val_accuracy: 0.6606 - val_loss: 0.7807\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 307ms/step - accuracy: 0.6637 - loss: 0.7547 - val_accuracy: 0.6657 - val_loss: 0.7744\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 291ms/step - accuracy: 0.6870 - loss: 0.7343 - val_accuracy: 0.6897 - val_loss: 0.7231\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 314ms/step - accuracy: 0.7106 - loss: 0.6915 - val_accuracy: 0.7045 - val_loss: 0.6961\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 308ms/step - accuracy: 0.7505 - loss: 0.6180 - val_accuracy: 0.6920 - val_loss: 0.6809\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 294ms/step - accuracy: 0.7569 - loss: 0.5899 - val_accuracy: 0.6845 - val_loss: 0.6989\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 327ms/step - accuracy: 0.7580 - loss: 0.5657 - val_accuracy: 0.7193 - val_loss: 0.6478\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 336ms/step - accuracy: 0.7731 - loss: 0.5225 - val_accuracy: 0.6937 - val_loss: 0.6962\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 316ms/step - accuracy: 0.7874 - loss: 0.5043 - val_accuracy: 0.7313 - val_loss: 0.6455\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 303ms/step - accuracy: 0.8009 - loss: 0.4536 - val_accuracy: 0.7148 - val_loss: 0.6536\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 315ms/step - accuracy: 0.8164 - loss: 0.4182 - val_accuracy: 0.7119 - val_loss: 0.7199\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.8166 - loss: 0.3907 - val_accuracy: 0.7114 - val_loss: 0.7358\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.7445 - loss: 0.6231\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.2\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 317ms/step - accuracy: 0.4880 - loss: 1.0037 - val_accuracy: 0.6212 - val_loss: 0.8616\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 311ms/step - accuracy: 0.6233 - loss: 0.8453 - val_accuracy: 0.6275 - val_loss: 0.8191\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 310ms/step - accuracy: 0.6651 - loss: 0.7913 - val_accuracy: 0.6731 - val_loss: 0.7740\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 314ms/step - accuracy: 0.6911 - loss: 0.7313 - val_accuracy: 0.6497 - val_loss: 0.7973\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 316ms/step - accuracy: 0.6833 - loss: 0.7335 - val_accuracy: 0.6942 - val_loss: 0.7045\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 298ms/step - accuracy: 0.7134 - loss: 0.6526 - val_accuracy: 0.6988 - val_loss: 0.6890\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 311ms/step - accuracy: 0.7367 - loss: 0.6359 - val_accuracy: 0.7028 - val_loss: 0.6981\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 314ms/step - accuracy: 0.7502 - loss: 0.6034 - val_accuracy: 0.6971 - val_loss: 0.7110\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 327ms/step - accuracy: 0.7497 - loss: 0.5690 - val_accuracy: 0.7182 - val_loss: 0.6655\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 313ms/step - accuracy: 0.7744 - loss: 0.5128 - val_accuracy: 0.7034 - val_loss: 0.7432\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.7858 - loss: 0.4825 - val_accuracy: 0.7233 - val_loss: 0.6834\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 318ms/step - accuracy: 0.7950 - loss: 0.4720 - val_accuracy: 0.7108 - val_loss: 0.7492\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.7232 - loss: 0.6516\n",
            "Training with combination: vector_size=300, window=25, negative=20, lstm_units=256, dropout_rate_lstm=0.5, dropout_rate_dense=0.4\n",
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 302ms/step - accuracy: 0.5347 - loss: 0.9837 - val_accuracy: 0.6241 - val_loss: 0.8633\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 315ms/step - accuracy: 0.6237 - loss: 0.8475 - val_accuracy: 0.6532 - val_loss: 0.7823\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 282ms/step - accuracy: 0.6593 - loss: 0.7815 - val_accuracy: 0.6817 - val_loss: 0.7402\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 316ms/step - accuracy: 0.6726 - loss: 0.7455 - val_accuracy: 0.6766 - val_loss: 0.7321\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 301ms/step - accuracy: 0.7072 - loss: 0.6932 - val_accuracy: 0.6823 - val_loss: 0.7234\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 314ms/step - accuracy: 0.7353 - loss: 0.6252 - val_accuracy: 0.6977 - val_loss: 0.6964\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 0.7506 - loss: 0.6083 - val_accuracy: 0.7108 - val_loss: 0.6546\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 315ms/step - accuracy: 0.7594 - loss: 0.5596 - val_accuracy: 0.7233 - val_loss: 0.6502\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 0.7684 - loss: 0.5349 - val_accuracy: 0.7114 - val_loss: 0.6526\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 0.7749 - loss: 0.5000 - val_accuracy: 0.6971 - val_loss: 0.6729\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 310ms/step - accuracy: 0.7845 - loss: 0.5045 - val_accuracy: 0.7091 - val_loss: 0.6781\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.7289 - loss: 0.6341\n",
            "Best Accuracy: 0.7313\n",
            "Best Parameters: {'vector_size': 300, 'window': 25, 'negative': 20, 'lstm_units': 256, 'dropout_rate_lstm': 0.4, 'dropout_rate_dense': 0.4}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import itertools\n",
        "\n",
        "# Define hyperparameter search spaces for Word2Vec and LSTM\n",
        "word2vec_params = {\n",
        "    'vector_size': [200, 300],\n",
        "    'window': [10, 25],\n",
        "    'negative': [10, 20],\n",
        "}\n",
        "\n",
        "lstm_params = {\n",
        "    'lstm_units': [64, 128, 256],\n",
        "    'dropout_rate_lstm': [0.4, 0.5],  # LSTM dropout rate\n",
        "    'dropout_rate_dense': [0.2, 0.4]  # Dense layer dropout rate\n",
        "}\n",
        "\n",
        "# Combine the parameters for Word2Vec and LSTM\n",
        "combinations = itertools.product(\n",
        "    word2vec_params['vector_size'],\n",
        "    word2vec_params['window'],\n",
        "    word2vec_params['negative'],\n",
        "    lstm_params['lstm_units'],\n",
        "    lstm_params['dropout_rate_lstm'],\n",
        "    lstm_params['dropout_rate_dense']\n",
        ")\n",
        "\n",
        "# Track the best model and its score\n",
        "best_score = float('-inf')\n",
        "best_params = None\n",
        "\n",
        "# Function to handle OOV words with a dedicated 'UNK' vector\n",
        "def get_word_vector(word, model, vector_size, unk_vector=None):\n",
        "    if word in model.wv:\n",
        "        return model.wv[word]\n",
        "    else:\n",
        "        if unk_vector is None:\n",
        "            return np.random.uniform(-0.25, 0.25, vector_size)\n",
        "        else:\n",
        "            return unk_vector\n",
        "\n",
        "# Iterate over each combination of hyperparameters\n",
        "for vector_size, window, negative, lstm_units, dropout_rate_lstm, dropout_rate_dense in combinations:\n",
        "    print(f\"Training with combination: vector_size={vector_size}, window={window}, \"\n",
        "          f\"negative={negative}, lstm_units={lstm_units}, \"\n",
        "          f\"dropout_rate_lstm={dropout_rate_lstm}, dropout_rate_dense={dropout_rate_dense}\")\n",
        "\n",
        "    # Train Word2Vec model\n",
        "    word2vec_model = Word2Vec(\n",
        "        vector_size=vector_size,\n",
        "        window=window,\n",
        "        sg=1,\n",
        "        negative=negative,\n",
        "        epochs=30\n",
        "    )\n",
        "\n",
        "    word2vec_model.build_vocab(texts_lower)\n",
        "    word2vec_model.train(texts_lower, total_examples=word2vec_model.corpus_count, epochs=30)\n",
        "\n",
        "    unk_vector = np.mean(word2vec_model.wv.vectors, axis=0)\n",
        "\n",
        "    vectorized_sentences = [[get_word_vector(word, word2vec_model, vector_size, unk_vector) for word in sentence] for sentence in texts_lower]\n",
        "\n",
        "    # Pad sequences\n",
        "    max_sequence_length = 30  # Set max sequence length based on your data\n",
        "    X = pad_sequences([np.array(sentence) for sentence in vectorized_sentences], maxlen=max_sequence_length, padding='post', dtype='float32')\n",
        "\n",
        "    # Encode the labels and split data into training and test sets\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(data['Sentiment'])  # Ensure 'data' contains 'Sentiment'\n",
        "    y = tf.keras.utils.to_categorical(y)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Build and compile LSTM model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(X.shape[1], X.shape[2])),\n",
        "        tf.keras.layers.LSTM(lstm_units, return_sequences=False),\n",
        "        tf.keras.layers.Dropout(dropout_rate_lstm),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(dropout_rate_dense),\n",
        "        tf.keras.layers.Dense(y.shape[1], activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=100, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "    if accuracy > best_score:\n",
        "        best_score = accuracy\n",
        "        best_params = {\n",
        "            'vector_size': vector_size,\n",
        "            'window': window,\n",
        "            'negative': negative,\n",
        "            'lstm_units': lstm_units,\n",
        "            'dropout_rate_lstm': dropout_rate_lstm,\n",
        "            'dropout_rate_dense': dropout_rate_dense\n",
        "        }\n",
        "\n",
        "# Print the best parameters and accuracy score\n",
        "print(f\"Best Accuracy: {best_score:.4f}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZDimFOGxyxu"
      },
      "source": [
        "Optimized Model with the selected parameters from Hyperparamter Tuning and unknow words handling but no Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq6jDD9H7T5B",
        "outputId": "f3a12751-ddd5-4634-d6ad-11ec4e6e7537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuzZLQWAQxWL",
        "outputId": "c5b46724-5f6d-4a3e-d879-04048a4ea4e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 301ms/step - accuracy: 0.5351 - loss: 0.9941 - val_accuracy: 0.6138 - val_loss: 0.8666\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 263ms/step - accuracy: 0.6151 - loss: 0.8584 - val_accuracy: 0.6087 - val_loss: 0.8540\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 293ms/step - accuracy: 0.6391 - loss: 0.7980 - val_accuracy: 0.6418 - val_loss: 0.7940\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 289ms/step - accuracy: 0.6636 - loss: 0.7636 - val_accuracy: 0.6572 - val_loss: 0.7692\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 293ms/step - accuracy: 0.7042 - loss: 0.6893 - val_accuracy: 0.6492 - val_loss: 0.7493\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 286ms/step - accuracy: 0.7059 - loss: 0.6563 - val_accuracy: 0.6794 - val_loss: 0.7688\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 293ms/step - accuracy: 0.7204 - loss: 0.6433 - val_accuracy: 0.6805 - val_loss: 0.7067\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 292ms/step - accuracy: 0.7316 - loss: 0.5928 - val_accuracy: 0.7005 - val_loss: 0.7098\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 292ms/step - accuracy: 0.7532 - loss: 0.5747 - val_accuracy: 0.6942 - val_loss: 0.7231\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 307ms/step - accuracy: 0.7732 - loss: 0.5111 - val_accuracy: 0.6680 - val_loss: 0.7367\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.6943 - loss: 0.6786\n",
            "Test Accuracy: 0.68\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import itertools\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from spellchecker import SpellChecker\n",
        "import numpy as np\n",
        "\n",
        "# Download necessary resources from nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Get the set of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.add('also')\n",
        "\n",
        "# Define punctuation characters to be removed (excluding common currency symbols)\n",
        "currency_symbols = '$€£¥₹'\n",
        "punctuation_to_remove = string.punctuation.replace('$', '').replace('€', '').replace('£', '').replace('¥', '').replace('₹', '')\n",
        "\n",
        "# Initialize the spell checker and lemmatizer\n",
        "spell = SpellChecker()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to preprocess text by lowercasing, removing punctuation, lemmatizing, and checking spelling\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase the text\n",
        "    text = re.sub(f\"[{re.escape(punctuation_to_remove)}]\", '', text)  # Remove unwanted punctuation\n",
        "    words = text.split()  # Tokenize by splitting on spaces\n",
        "    filtered_words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    return filtered_words  # Return tokenized, meaningful, and lemmatized list of words\n",
        "\n",
        "# Assuming data['Sentence'] contains the text data as a list of sentences\n",
        "texts_lower = [preprocess_text(sentence) for sentence in data['Sentence']]  # Preprocess all sentences\n",
        "\n",
        "# Initialize Word2Vec model (now correctly added)\n",
        "word2vec_model = Word2Vec(vector_size=300, window=25, sg=1, negative=20, min_count=1)\n",
        "\n",
        "# Function to handle OOV words with a dedicated 'UNK' vector\n",
        "def get_word_vector(word, model, vector_size, unk_vector=None):\n",
        "    if word in model.wv:\n",
        "        return model.wv[word]\n",
        "    else:\n",
        "        # Return the 'UNK' vector (learned during training) or initialize a random one\n",
        "        if unk_vector is None:\n",
        "            return np.random.uniform(-0.25, 0.25, vector_size)\n",
        "        else:\n",
        "            return unk_vector\n",
        "\n",
        "# Build the vocabulary and train Word2Vec\n",
        "word2vec_model.build_vocab(texts_lower)\n",
        "word2vec_model.train(texts_lower, total_examples=word2vec_model.corpus_count, epochs=30)\n",
        "\n",
        "# Optionally define an 'UNK' vector as the average of all word vectors\n",
        "unk_vector = np.mean(word2vec_model.wv.vectors, axis=0)\n",
        "\n",
        "# Convert sentences to sequences of word vectors\n",
        "vectorized_sentences = []\n",
        "for sentence in texts_lower:\n",
        "    vectorized_sentence = [get_word_vector(word, word2vec_model, 350, unk_vector) for word in sentence]\n",
        "    vectorized_sentences.append(vectorized_sentence)\n",
        "\n",
        "# Define the maximum sequence length for LSTM input\n",
        "max_sequence_length = 30  # Adjust based on your dataset and text length\n",
        "\n",
        "# Pad sequences to ensure uniform input length for the LSTM\n",
        "# Padding will ensure that all sentences have the same length\n",
        "X = pad_sequences([np.array(sentence) for sentence in vectorized_sentences],\n",
        "                  maxlen=max_sequence_length,\n",
        "                  padding='post',\n",
        "                  dtype='float32')\n",
        "\n",
        "# Encode the labels (assuming binary or multiclass classification)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['Sentiment'])  # Assuming 'Sentiment' column exists in `data`\n",
        "y = tf.keras.utils.to_categorical(y)  # One-hot encode labels for multi-class classification\n",
        "\n",
        "\n",
        "# Add EarlyStopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build the LSTM model for text classification\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X.shape[1], X.shape[2])),\n",
        "    tf.keras.layers.LSTM(256, return_sequences=False),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(y.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=100,callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}